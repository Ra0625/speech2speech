{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/ubuntu/speech2speech')\n",
    "sys.path.append(os.path.abspath(os.path.dirname('/home/ubuntu/speech2speech') + '/..'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from torchviz import make_dot, make_dot_from_trace\n",
    "import random\n",
    "from torchsummary import summary\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import umap\n",
    "from six.moves import xrange\n",
    "from scipy.signal import savgol_filter\n",
    "import pathlib\n",
    "import librosa.display\n",
    "import librosa\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "from speech2speech.models.training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class speech2speech:\n",
    "\n",
    "    def __init__():\n",
    "        self._device = \"cpu\"\n",
    "    \n",
    "    def inference(self, path_to_model, path_audio_input, speaker_id = '260'):\n",
    "        \"\"\"\n",
    "        initialize object \n",
    "\n",
    "        params:\n",
    "            path_to_model: pretrain model\n",
    "        \"\"\"\n",
    "        self._model = model.load_state_dict(torch.load(path_to_model)['state_dict'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
