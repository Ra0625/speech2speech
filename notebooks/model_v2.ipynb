{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd       \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "from __future__ import print_function\n",
    "import pathlib\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "\n",
    "from six.moves import xrange\n",
    "\n",
    "import umap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T20:46:23.928833Z",
     "start_time": "2020-01-22T20:46:23.920992Z"
    }
   },
   "outputs": [],
   "source": [
    "# PATHS \n",
    "\n",
    "raw_data = '/home/ubuntu/voice_conversion/data/raw/VCTK-Corpus'\n",
    "interim_data = os.path.join('/home/ubuntu/voice_conversion/data', 'interim')\n",
    "spectogram_array_path =  os.path.join(interim_data, 'spectogram_array')\n",
    "spectrogram_path =os.path.join(interim_data, 'spectogram') \n",
    "audio_path = '/home/ubuntu/voice_conversion/data/raw/VCTK-Corpus/wav48/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/ubuntu/voice_conversion/data/interim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-ffb4921c88be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# MKDIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ubuntu/voice_conversion/data/interim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/ubuntu/voice_conversion/data/interim'"
     ]
    }
   ],
   "source": [
    "# MKDIR\n",
    "os.mkdir('/home/ubuntu/voice_conversion/data/interim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[Errno 17] File exists: '/home/ubuntu/voice_conversion/data/interim/spectogram_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5dacf99b7ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectogram_array_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/ubuntu/voice_conversion/data/interim/spectogram_array'"
     ]
    }
   ],
   "source": [
    "os.mkdir(spectogram_array_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "files_np = list(glob.glob(os.path.join(spectogram_array_path,'*.*')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "Y_list = []\n",
    "for file in files_np: \n",
    "    trial_x = np.load(file)\n",
    "    trial_x =torch.tensor(trial_x, device='cpu').float()\n",
    "    trial_y = file.split('spectogram_array/')[1].split('_')[0][-3:]\n",
    "    trial_y =torch.tensor(int(trial_y), device='cpu').float()\n",
    "    X_list.append(trial_x)\n",
    "    Y_list.append(trial_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nX_list = []\n",
    "col_shape = []\n",
    "for file in files_np: \n",
    "    trial_x = np.load(file)\n",
    "    _, cols = trial_x.shape\n",
    "    nX_list.append(trial_x)\n",
    "    col_shape.append(cols)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(col_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,a in enumerate(nX_list):\n",
    "  rows, cols = a.shape\n",
    "  #print(rows, cols)\n",
    "  if cols != max(col_shape):\n",
    "    nX_list[i] = np.hstack([a, np.zeros(( rows, max(col_shape) - cols), dtype=a.dtype)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "for file in nX_list: \n",
    "    trial_x =torch.tensor(file, device='cpu').float()\n",
    "    X_list.append(trial_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = nX_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Tensor= torch.stack(X_list).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_Tensor= torch.stack(Y_list).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tensordataset = torch.utils.data.TensorDataset(x_Tensor, y_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = torch.utils.data.DataLoader(training_tensordataset, batch_size= 10 , shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Quantizer Layer\n",
    "\n",
    "This layer takes a tensor to be quantized. The channel dimension will be used as the space in which to quantize. All other dimensions will be flattened and will be seen as different examples to quantize.\n",
    "\n",
    "The output tensor will have the same shape as the input.\n",
    "\n",
    "As an example for a `BCHW` tensor of shape `[16, 64, 32, 32]`, we will first convert it to an `BHWC` tensor of shape `[16, 32, 32, 64]` and then reshape it into `[16384, 64]` and all `16384` vectors of size `64`  will be quantized independently. In otherwords, the channels are used as the space in which to quantize. All other dimensions will be flattened and be seen as different examples to quantize, `16384` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_training_updates = 1500\n",
    "\n",
    "# Encoder\n",
    "num_hiddens = 768\n",
    "num_residual_hiddens = 32\n",
    "num_residual_layers = 2\n",
    "# input_dim: 256\n",
    "\n",
    "# VQ\n",
    "# This value is not that important, usually 64 works.\n",
    "# This will not change the capacity in the information-bottleneck.\n",
    "embedding_dim = 64\n",
    "# The higher this value, the higher the capacity in the information bottleneck.\n",
    "num_embeddings = 29\n",
    "\n",
    "commitment_cost = 0.25\n",
    "\n",
    "decay = -0.99\n",
    "\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, device):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
    "        self._commitment_cost = commitment_cost\n",
    "        self._device = device\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(1, 2, 0).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        print('shape of inputs in VectorQuantizer.forward',inputs.shape)\n",
    "        _, time, batch_size = input_shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        print('shape of flat_input in VectorQuantizer.forward',flat_input.size())\n",
    "        print('device of flat_input',flat_input.device)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        print('shape of quantized in VectorQuantizer.forward',quantized.size())\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        q_latent_loss = F.mse_loss(quantized, inputs.detach())\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        #print(\"with inputs quantized: \"quantized.size())\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return loss, quantized.permute(2, 0, 1).contiguous(), perplexity, encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizerv2(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, device):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.uniform_(-1/self._num_embeddings, 1/self._num_embeddings)\n",
    "        self._commitment_cost = commitment_cost\n",
    "        self._device = device\n",
    "\n",
    "    def forward(self, inputs, record_codebook_stats=False):\n",
    "        \n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(1, 2, 0).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        print('shape of inputs in VectorQuantizer.forward',inputs.shape)\n",
    "        _, time, batch_size = input_shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        print('shape of flat_input in VectorQuantizer.forward',flat_input.size())\n",
    "        print('device of flat_input',flat_input.device)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        print('shape of quantized in VectorQuantizer.forward',quantized.size())\n",
    "        \n",
    "        concatenated_quantized = self._embedding.weight[torch.argmin(distances, dim=1).detach().cpu()] if not self.training or record_codebook_stats else None\n",
    "        \n",
    "        # Losses\n",
    "        e_latent_loss = torch.mean((quantized.detach() - inputs)**2)\n",
    "        q_latent_loss = torch.mean((quantized - inputs.detach())**2)\n",
    "        commitment_loss = self._commitment_cost * e_latent_loss\n",
    "        vq_loss = q_latent_loss + commitment_loss\n",
    "\n",
    "        quantized = inputs + (quantized - inputs).detach() # Trick to prevent backpropagation of quantized\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        \n",
    "        \"\"\"\n",
    "        The perplexity a useful value to track during training.\n",
    "        It indicates how many codes are 'active' on average.\n",
    "        \"\"\"\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10))) # Exponential entropy\n",
    "        \n",
    "        print(\"with inputs quantized: \",quantized.size())\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return vq_loss, quantized.permute(2, 0, 1).contiguous(), \\\n",
    "            perplexity, encodings.view(batch_size, time, -1), \\\n",
    "            distances.view(batch_size, time, -1), encoding_indices, \\\n",
    "            {'e_latent_loss': e_latent_loss.item(), 'q_latent_loss': q_latent_loss.item(),\n",
    "            'commitment_loss': commitment_loss.item(), 'vq_loss': vq_loss.item()}, \\\n",
    "             concatenated_quantized\n",
    "        #return loss, quantized.permute(2, 0, 1).contiguous(), perplexity, encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also implement a slightly modified version  which will use exponential moving averages to update the embedding vectors instead of an auxillary loss. This has the advantage that the embedding updates are independent of the choice of optimizer for the encoder, decoder and other parts of the architecture. For most experiments the EMA version trains faster than the non-EMA version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizerEMA(nn.Module):\n",
    "    \"\"\"\n",
    "    Inspired from Sonnet implementation of VQ-VAE https://arxiv.org/abs/1711.00937,\n",
    "    in https://github.com/deepmind/sonnet/blob/master/sonnet/python/modules/nets/vqvae.py and\n",
    "    pytorch implementation of it from zalandoresearch in https://github.com/zalandoresearch/pytorch-vq-vae/blob/master/vq-vae.ipynb.\n",
    "    Implements a slightly modified version of the algorithm presented in\n",
    "    'Neural Discrete Representation Learning' by van den Oord et al.\n",
    "    https://arxiv.org/abs/1711.00937\n",
    "    The difference between VectorQuantizerEMA and VectorQuantizer is that\n",
    "    this module uses exponential moving averages to update the embedding vectors\n",
    "    instead of an auxiliary loss. This has the advantage that the embedding\n",
    "    updates are independent of the choice of optimizer (SGD, RMSProp, Adam, K-Fac,\n",
    "    ...) used for the encoder, decoder and other parts of the architecture. For\n",
    "    most experiments the EMA version trains faster than the non-EMA version.\n",
    "    Input any tensor to be quantized. Last dimension will be used as space in\n",
    "    which to quantize. All other dimensions will be flattened and will be seen\n",
    "    as different examples to quantize.\n",
    "    The output tensor will have the same shape as the input.\n",
    "    For example a tensor with shape [16, 32, 32, 64] will be reshaped into\n",
    "    [16384, 64] and all 16384 vectors (each of 64 dimensions)  will be quantized\n",
    "    independently.\n",
    "    Args:\n",
    "        embedding_dim: integer representing the dimensionality of the tensors in the\n",
    "            quantized space. Inputs to the modules must be in this format as well.\n",
    "        num_embeddings: integer, the number of vectors in the quantized space.\n",
    "            commitment_cost: scalar which controls the weighting of the loss terms (see\n",
    "            equation 4 in the paper).\n",
    "        decay: float, decay for the moving averages.\n",
    "        epsilon: small float constant to avoid numerical instability.\n",
    "    \"\"\"\n",
    "        \n",
    "        \n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay, device, epsilon=1e-5):\n",
    "           \n",
    "        super(VectorQuantizerEMA, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.normal_()\n",
    "        self._commitment_cost = commitment_cost\n",
    "        \n",
    "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
    "        self._ema_w = nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
    "        self._ema_w.data.normal_()\n",
    "        \n",
    "        self._decay = decay\n",
    "        self._epsilon = epsilon\n",
    "        self._device = device\n",
    "\n",
    "    def forward(self, inputs, compute_distances_if_possible=True, record_codebook_stats=False):\n",
    "        \"\"\"\n",
    "        Connects the module to some inputs.\n",
    "        Args:\n",
    "            inputs: Tensor, final dimension must be equal to embedding_dim. All other\n",
    "                leading dimensions will be flattened and treated as a large batch.\n",
    "        \n",
    "        Returns:\n",
    "            loss: Tensor containing the loss to optimize.\n",
    "            quantize: Tensor containing the quantized version of the input.\n",
    "            perplexity: Tensor containing the perplexity of the encodings.\n",
    "            encodings: Tensor containing the discrete encodings, ie which element\n",
    "                of the quantized space each input element was mapped to.\n",
    "            distances\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        inputs = inputs.permute(1, 2, 0).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "        \"\"\"\n",
    "        encoding_indices: Tensor containing the discrete encoding indices, ie\n",
    "        which element of the quantized space each input element was mapped to.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, dtype=torch.float).to(self._device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Compute distances between encoding vectors\n",
    "        if not self.training and compute_distances_if_possible:\n",
    "            _encoding_distances = [torch.dist(items[0], items[1], 2).to(self._device) for items in combinations(flat_input, r=2)]\n",
    "            encoding_distances = torch.tensor(_encoding_distances).to(self._device).view(batch_size, -1)\n",
    "        else:\n",
    "            encoding_distances = None\n",
    "\n",
    "        # Compute distances between embedding vectors\n",
    "        if not self.training and compute_distances_if_possible:\n",
    "            _embedding_distances = [torch.dist(items[0], items[1], 2).to(self._device) for items in combinations(self._embedding.weight, r=2)]\n",
    "            embedding_distances = torch.tensor(_embedding_distances).to(self._device)\n",
    "        else:\n",
    "            embedding_distances = None\n",
    "\n",
    "        # Sample nearest embedding\n",
    "        if not self.training and compute_distances_if_possible:\n",
    "            _frames_vs_embedding_distances = [torch.dist(items[0], items[1], 2).to(self._device) for items in product(flat_input, self._embedding.weight.detach())]\n",
    "            frames_vs_embedding_distances = torch.tensor(_frames_vs_embedding_distances).to(self._device).view(batch_size, time, -1)\n",
    "        else:\n",
    "            frames_vs_embedding_distances = None\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # Use EMA to update the embedding vectors\n",
    "        if self.training:\n",
    "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
    "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
    "            \n",
    "            # Laplace smoothing of the cluster size\n",
    "            n = torch.sum(self._ema_cluster_size.data)\n",
    "            self._ema_cluster_size = (\n",
    "                (self._ema_cluster_size + self._epsilon)\n",
    "                / (n + self._num_embeddings * self._epsilon) * n)\n",
    "            \n",
    "            dw = torch.matmul(encodings.t(), flat_input)\n",
    "            self._ema_w = nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
    "            \n",
    "            self._embedding.weight = nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        concatenated_quantized = self._embedding.weight[torch.argmin(distances, dim=1).detach().cpu()] if not self.training or record_codebook_stats else None\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = torch.mean((quantized.detach() - inputs)**2)\n",
    "        loss = self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        # Straight Through Estimator\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        \"\"\"\n",
    "        The perplexity a useful value to track during training.\n",
    "        It indicates how many codes are 'active' on average.\n",
    "        \"\"\"\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return loss, quantized.permute(2, 0, 1).contiguous(), perplexity, encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder & Decoder Architecture\n",
    "\n",
    "The encoder and decoder architecture is based on a ResNet and is implemented below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        \"\"\"\n",
    "        2 preprocessing convolution layers with filter length 3\n",
    "        and residual connections.\n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        self._conv_1 = nn.Conv1d(in_channels= 1025, #??features_filters,\n",
    "                                 out_channels=num_hiddens,\n",
    "                                 kernel_size=3,\n",
    "                                 padding=1)\n",
    "        \n",
    "        self._conv_2 = nn.Conv1d(in_channels=num_hiddens,\n",
    "                                 out_channels=num_hiddens,\n",
    "                                 kernel_size=3,\n",
    "                                 padding=1)\n",
    "        \"\"\"\n",
    "        1 strided convolution length reduction layer with filter\n",
    "        length 4 and stride 2 (downsampling the signal by a factor\n",
    "        of two).\n",
    "        \"\"\"\n",
    "        \n",
    "        self._conv_3 = nn.Conv1d(in_channels=num_hiddens,\n",
    "                                 out_channels=num_hiddens,\n",
    "                                 kernel_size=4,\n",
    "                                 stride=1, \n",
    "                                 padding=2)\n",
    "        \"\"\"\n",
    "        2 convolutional layers with length 3 and\n",
    "        residual connections.\n",
    "        \"\"\"\n",
    "        self._conv_4 = nn.Conv1d(in_channels=num_hiddens,\n",
    "                                 out_channels=num_hiddens,\n",
    "                                 kernel_size=3,\n",
    "                                 padding=1)\n",
    "        \n",
    "        self._conv_5 = nn.Conv1d(in_channels=num_hiddens,\n",
    "                                 out_channels=num_hiddens,\n",
    "                                 kernel_size=3,\n",
    "                                 padding=1)\n",
    "        \n",
    "        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n",
    "                                             num_hiddens=num_hiddens,\n",
    "                                             num_residual_layers=num_residual_layers,\n",
    "                                             num_residual_hiddens=num_residual_hiddens)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        print('shape of inputs in Encoder.forward',inputs.size())\n",
    "\n",
    "        x_conv_1 = F.relu(self._conv_1(inputs))\n",
    "        print('shape of x in Encoder.forward._conv_1',x_conv_1.size())\n",
    "\n",
    "        x = F.relu(self._conv_2(x_conv_1)) + x_conv_1\n",
    "        print('shape of x in Encoder.forward.relu_2',x.size())\n",
    "        \n",
    "        x_conv_3 = F.relu(self._conv_3(x))\n",
    "        print('shape of x_conv_3 in Encoder.forward._conv_3',x_conv_3.size())\n",
    "        \n",
    "        x_conv_4 = F.relu(self._conv_4(x_conv_3)) + x_conv_3\n",
    "        print('shape of x_conv_4 in Encoder.forward._conv_4',x_conv_4.size())\n",
    "        \n",
    "        x_conv_5 = F.relu(self._conv_5(x_conv_4)) + x_conv_4\n",
    "        print('shape of x_conv_5 in Encoder.forward._conv_5',x_conv_5.size())\n",
    "        \n",
    "        x = self._residual_stack(x_conv_5) + x_conv_5\n",
    "        print('shape of _residual_stack in Encoder.forward',x.size())\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_hiddens):\n",
    "        \n",
    "        super(Residual, self).__init__()\n",
    "        \n",
    "        self._block = nn.Sequential(\n",
    "            \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv1d(\n",
    "                     in_channels=in_channels,\n",
    "                      out_channels=num_residual_hiddens,\n",
    "                      kernel_size=3, \n",
    "                      stride=1, \n",
    "                      padding=1, \n",
    "                      bias=False),\n",
    "            \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.Conv1d(in_channels=num_residual_hiddens,\n",
    "                      out_channels=num_hiddens,\n",
    "                      kernel_size=1, \n",
    "                      stride=1, \n",
    "                      bias=False)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print('shape of x in Residual.forward',x.size())\n",
    "        return x + self._block(x)\n",
    "\n",
    "\n",
    "class ResidualStack(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super(ResidualStack, self).__init__()\n",
    "        \n",
    "        self._num_residual_layers = num_residual_layers\n",
    "        self._layers = nn.ModuleList([Residual(in_channels, num_hiddens, num_residual_hiddens)\n",
    "                             for _ in range(self._num_residual_layers)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        print('shape of x in ResidualStack.forward',x.size())\n",
    "        for i in range(self._num_residual_layers):\n",
    "            x = self._layers[i](x)\n",
    "            print(f'Iteration {i} shape of x in ResidualStack.forward {x.size()} ',)\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, num_hiddens, num_residual_layers, num_residual_hiddens):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self._conv_1 = nn.Conv1d(in_channels=in_channels,\n",
    "                                 out_channels=num_hiddens,\n",
    "                                 kernel_size=3,\n",
    "                                 padding=1)\n",
    "        \n",
    "        self._upsample = nn.Upsample(scale_factor=2)\n",
    "        \n",
    "        self._residual_stack = ResidualStack(in_channels=num_hiddens,\n",
    "                                             num_hiddens=num_hiddens,\n",
    "                                             num_residual_layers=num_residual_layers,\n",
    "                                             num_residual_hiddens=num_residual_hiddens)\n",
    "        \n",
    "        self._conv_trans_1 = nn.ConvTranspose1d(in_channels=num_hiddens, \n",
    "                                                out_channels=num_hiddens,\n",
    "                                                kernel_size=3, \n",
    "                                                padding=1)\n",
    "        \n",
    "        self._conv_trans_2 = nn.ConvTranspose1d(in_channels=num_hiddens, \n",
    "                                                out_channels=num_hiddens,\n",
    "                                                kernel_size=3,  \n",
    "                                                padding=0)\n",
    "        \n",
    "        self._conv_trans_3 = nn.ConvTranspose1d(in_channels=num_hiddens, \n",
    "                                                out_channels=1025,#out_channels\n",
    "                                                kernel_size=3, \n",
    "                                                padding=3)\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):#, speaker_dic, speaker_id\n",
    "        print('shape of inputs in Decoder.forward',inputs.size())\n",
    "        x = self._conv_1(inputs)\n",
    "        print('shape of x in Decoder.forward._conv_1',x.size())\n",
    "        \n",
    "        x = self._upsample(x)\n",
    "        print('shape of x in Decoder.forward._upsample',x.size())\n",
    "        \n",
    "        x = self._residual_stack(x)\n",
    "        print('shape of x in Decoder.forward._residual_stack',x.size())\n",
    "        \n",
    "        x = self._conv_trans_1(x)\n",
    "        print('shape of x in Decoder.forward._conv_trans_1',x.size())\n",
    "        \n",
    "        x = F.relu(x)#self._conv_trans_1(x)\n",
    "        print('shape of x in Decoder.forward._conv_trans_1',x.size())\n",
    "        \n",
    "        x = F.relu(self._conv_trans_2(x))\n",
    "        print('shape of x in Decoder.forward._conv_trans_2',x.size())\n",
    "        \n",
    "        x = self._conv_trans_3(x)\n",
    "        print('shape of x in Decoder.forward._conv_trans_3',x.size())\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TWEAK THE OUTPUT \n",
    "# https://pytorch.org/docs/stable/nn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "We use the hyperparameters from the author's code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_loader = DataLoader(training_data, \n",
    "#                             batch_size=batch_size, \n",
    "#                             shuffle=True,\n",
    "#                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation_loader = DataLoader(validation_data,\n",
    "#                               batch_size=32,\n",
    "#                               shuffle=True,\n",
    "#                               pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, num_hiddens, num_residual_layers, num_residual_hiddens, \n",
    "                 num_embeddings, embedding_dim, commitment_cost, decay=0):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self._encoder = Encoder(1, num_hiddens,\n",
    "                                num_residual_layers, \n",
    "                                num_residual_hiddens)\n",
    "        self._pre_vq_conv = nn.Conv1d(in_channels=num_hiddens, \n",
    "                                      out_channels=embedding_dim,\n",
    "                                      kernel_size=1, \n",
    "                                      stride=1)\n",
    "        if decay > 0.0:\n",
    "            self._vq_vae = VectorQuantizerEMA(num_embeddings, embedding_dim, \n",
    "                                              commitment_cost, decay)\n",
    "        else:\n",
    "            self._vq_vae = VectorQuantizer(num_embeddings, embedding_dim,\n",
    "                                           commitment_cost, device)\n",
    "        self._decoder = Decoder(embedding_dim,\n",
    "                                num_hiddens, \n",
    "                                num_residual_layers, \n",
    "                                num_residual_hiddens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(\"Model::forward\")\n",
    "        #print(x.size())\n",
    "        z = self._encoder(x)\n",
    "        z = self._pre_vq_conv(z)\n",
    "        loss, quantized, perplexity, _ = self._vq_vae(z)\n",
    "        #vq_loss, quantized, perplexity, _, _, encoding_indices, \\\n",
    "        #losses, concatenated_quantized = self._vq_vae(z)\n",
    "        #print(\"quantized \")\n",
    "        #print( quantized.size())\n",
    "        x_recon = self._decoder(quantized)\n",
    "        \n",
    "        input_features_size = x.size(2)\n",
    "        print('input_features_size', input_features_size)\n",
    "        output_features_size = x_recon.size(2)\n",
    "        print('output_features_size', output_features_size)\n",
    "        \n",
    "        x_recon = x_recon.view(-1, 1025, output_features_size)\n",
    "        x_recon = x_recon[:, :, :-(output_features_size-input_features_size)]\n",
    "        print('x_recon size', x_recon.size())\n",
    "\n",
    "        return loss, x_recon, perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(num_hiddens, num_residual_layers, num_residual_hiddens,\n",
    "              num_embeddings, embedding_dim, \n",
    "              commitment_cost, decay).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (_encoder): Encoder(\n",
       "    (_conv_1): Conv1d(1025, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_2): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_3): Conv1d(768, 768, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (_conv_4): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_5): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_residual_stack): ResidualStack(\n",
       "      (_layers): ModuleList(\n",
       "        (0): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_pre_vq_conv): Conv1d(768, 64, kernel_size=(1,), stride=(1,))\n",
       "  (_vq_vae): VectorQuantizer(\n",
       "    (_embedding): Embedding(29, 64)\n",
       "  )\n",
       "  (_decoder): Decoder(\n",
       "    (_conv_1): Conv1d(64, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (_residual_stack): ResidualStack(\n",
       "      (_layers): ModuleList(\n",
       "        (0): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_conv_trans_1): ConvTranspose1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_trans_2): ConvTranspose1d(768, 768, kernel_size=(3,), stride=(1,))\n",
       "    (_conv_trans_3): ConvTranspose1d(768, 1025, kernel_size=(3,), stride=(1,), padding=(3,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([2, 1025, 326])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([2, 768, 326])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([2, 768, 326])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([2, 768, 327])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([2, 768, 327])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([2, 768, 327])\n",
      "shape of x in ResidualStack.forward torch.Size([2, 768, 327])\n",
      "shape of x in Residual.forward torch.Size([2, 768, 327])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([2, 768, 327]) \n",
      "shape of x in Residual.forward torch.Size([2, 768, 327])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([2, 768, 327]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([2, 768, 327])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 327, 2])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([654, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 327, 2])\n",
      "shape of inputs in Decoder.forward torch.Size([2, 64, 327])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([2, 768, 327])\n",
      "shape of x in Decoder.forward._upsample torch.Size([2, 768, 654])\n",
      "shape of x in ResidualStack.forward torch.Size([2, 768, 654])\n",
      "shape of x in Residual.forward torch.Size([2, 768, 654])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([2, 768, 654]) \n",
      "shape of x in Residual.forward torch.Size([2, 768, 654])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([2, 768, 654]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([2, 768, 654])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([2, 768, 654])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([2, 768, 654])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([2, 768, 656])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([2, 1025, 652])\n",
      "input_features_size 326\n",
      "output_features_size 652\n",
      "x_recon size torch.Size([2, 1025, 326])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 768, 326]       2,362,368\n",
      "            Conv1d-2             [-1, 768, 326]       1,770,240\n",
      "            Conv1d-3             [-1, 768, 327]       2,360,064\n",
      "            Conv1d-4             [-1, 768, 327]       1,770,240\n",
      "            Conv1d-5             [-1, 768, 327]       1,770,240\n",
      "              ReLU-6             [-1, 768, 327]               0\n",
      "            Conv1d-7              [-1, 32, 327]          73,728\n",
      "              ReLU-8              [-1, 32, 327]               0\n",
      "            Conv1d-9             [-1, 768, 327]          24,576\n",
      "         Residual-10             [-1, 768, 327]               0\n",
      "             ReLU-11             [-1, 768, 327]               0\n",
      "           Conv1d-12              [-1, 32, 327]          73,728\n",
      "             ReLU-13              [-1, 32, 327]               0\n",
      "           Conv1d-14             [-1, 768, 327]          24,576\n",
      "         Residual-15             [-1, 768, 327]               0\n",
      "    ResidualStack-16             [-1, 768, 327]               0\n",
      "          Encoder-17             [-1, 768, 327]               0\n",
      "           Conv1d-18              [-1, 64, 327]          49,216\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-aaa89d5807d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m326\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     91\u001b[0m         )\n\u001b[1;32m     92\u001b[0m         \u001b[0mtotal_params\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nb_params\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtotal_output\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"trainable\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"trainable\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mprod\u001b[0;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2770\u001b[0m     \"\"\"\n\u001b[1;32m   2771\u001b[0m     return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2772\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "summary(model, (1025, 326))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m(86)\u001b[0;36m_wrapreduction\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     84 \u001b[0;31m                \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     85 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 86 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     87 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     88 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in training_loader:\n",
    "    train = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 326])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 326])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 326])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 327])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 327])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 327])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 327])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 327])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 327]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 327])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 327]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 327])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 327, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([3270, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 327, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 327])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 327])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 654])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 654])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 654])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 654]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 654])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 654]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 654])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 654])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 654])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 656])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 652])\n",
      "input_features_size 326\n",
      "output_features_size 652\n",
      "x_recon size torch.Size([10, 1025, 326])\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"823pt\" height=\"3175pt\"\n",
       " viewBox=\"0.00 0.00 823.45 3175.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(.5795 .5795) rotate(0) translate(4 5475)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-5475 1417,-5475 1417,4 -4,4\"/>\n",
       "<!-- 140341126750784 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140341126750784</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"504.5,-2203 412.5,-2203 412.5,-2182 504.5,-2182 504.5,-2203\"/>\n",
       "<text text-anchor=\"middle\" x=\"458.5\" y=\"-2189.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126750896 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140341126750896</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"453.5,-2266.5 345.5,-2266.5 345.5,-2245.5 453.5,-2245.5 453.5,-2266.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.5\" y=\"-2252.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MseLossBackward</text>\n",
       "</g>\n",
       "<!-- 140341126750896&#45;&gt;140341126750784 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140341126750896&#45;&gt;140341126750784</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M409.5085,-2245.2281C418.2918,-2235.7749 431.2477,-2221.8309 441.6303,-2210.6564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"444.3966,-2212.8211 448.6393,-2203.1128 439.2684,-2208.0564 444.3966,-2212.8211\"/>\n",
       "</g>\n",
       "<!-- 140341126751064 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140341126751064</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"445.5,-2336.5 353.5,-2336.5 353.5,-2315.5 445.5,-2315.5 445.5,-2336.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.5\" y=\"-2322.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751064&#45;&gt;140341126750896 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140341126751064&#45;&gt;140341126750896</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M399.5,-2315.3685C399.5,-2305.1925 399.5,-2289.5606 399.5,-2276.8912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"403.0001,-2276.7315 399.5,-2266.7315 396.0001,-2276.7316 403.0001,-2276.7315\"/>\n",
       "</g>\n",
       "<!-- 140341126751176 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140341126751176</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"442,-2400 357,-2400 357,-2379 442,-2379 442,-2400\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.5\" y=\"-2386.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751176&#45;&gt;140341126751064 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140341126751176&#45;&gt;140341126751064</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M399.5,-2378.7281C399.5,-2370.0091 399.5,-2357.4699 399.5,-2346.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"403.0001,-2346.6128 399.5,-2336.6128 396.0001,-2346.6129 403.0001,-2346.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126751288 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140341126751288</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"476.5,-2470 322.5,-2470 322.5,-2436 476.5,-2436 476.5,-2470\"/>\n",
       "<text text-anchor=\"middle\" x=\"399.5\" y=\"-2456.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_vq_vae._embedding.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"399.5\" y=\"-2443.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (29, 64)</text>\n",
       "</g>\n",
       "<!-- 140341126751288&#45;&gt;140341126751176 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140341126751288&#45;&gt;140341126751176</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M399.5,-2435.9832C399.5,-2428.1157 399.5,-2418.6973 399.5,-2410.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"403.0001,-2410.3686 399.5,-2400.3687 396.0001,-2410.3687 403.0001,-2410.3686\"/>\n",
       "</g>\n",
       "<!-- 140341126750952 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140341126750952</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"563,-2266.5 472,-2266.5 472,-2245.5 563,-2245.5 563,-2266.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"517.5\" y=\"-2252.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126750952&#45;&gt;140341126750784 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140341126750952&#45;&gt;140341126750784</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M507.4915,-2245.2281C498.7082,-2235.7749 485.7523,-2221.8309 475.3697,-2210.6564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"477.7316,-2208.0564 468.3607,-2203.1128 472.6034,-2212.8211 477.7316,-2208.0564\"/>\n",
       "</g>\n",
       "<!-- 140341126751120 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140341126751120</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"579.5,-2336.5 481.5,-2336.5 481.5,-2315.5 579.5,-2315.5 579.5,-2336.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"530.5\" y=\"-2322.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126751120&#45;&gt;140341126750952 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140341126751120&#45;&gt;140341126750952</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M528.5256,-2315.3685C526.6358,-2305.1925 523.7327,-2289.5606 521.3798,-2276.8912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.7602,-2275.9243 519.493,-2266.7315 517.8778,-2277.2025 524.7602,-2275.9243\"/>\n",
       "</g>\n",
       "<!-- 140341126751344 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140341126751344</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"590,-2400 497,-2400 497,-2379 590,-2379 590,-2400\"/>\n",
       "<text text-anchor=\"middle\" x=\"543.5\" y=\"-2386.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126751344&#45;&gt;140341126751120 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140341126751344&#45;&gt;140341126751120</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M541.2947,-2378.7281C539.491,-2369.9174 536.8885,-2357.2055 534.6909,-2346.4708\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"538.1073,-2345.7076 532.6727,-2336.6128 531.2495,-2347.1116 538.1073,-2345.7076\"/>\n",
       "</g>\n",
       "<!-- 140341126751512 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140341126751512</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"603.5,-2463.5 513.5,-2463.5 513.5,-2442.5 603.5,-2442.5 603.5,-2463.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"558.5\" y=\"-2449.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126751512&#45;&gt;140341126751344 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140341126751512&#45;&gt;140341126751344</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M555.9555,-2442.2281C553.8742,-2433.4174 550.8714,-2420.7055 548.3356,-2409.9708\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"551.7122,-2409.0403 546.007,-2400.1128 544.8997,-2410.6496 551.7122,-2409.0403\"/>\n",
       "</g>\n",
       "<!-- 140341126751624 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140341126751624</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"660.5,-2527 564.5,-2527 564.5,-2506 660.5,-2506 660.5,-2527\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-2513.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CopyBackwards</text>\n",
       "</g>\n",
       "<!-- 140341126751624&#45;&gt;140341126751512 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140341126751624&#45;&gt;140341126751512</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M603.3396,-2505.7281C595.3788,-2496.3667 583.6727,-2482.6012 574.2175,-2471.4826\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"576.6696,-2468.9634 567.5251,-2463.6128 571.3371,-2473.4982 576.6696,-2468.9634\"/>\n",
       "</g>\n",
       "<!-- 140341126808128 -->\n",
       "<g id=\"node109\" class=\"node\">\n",
       "<title>140341126808128</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"717.5,-2463.5 625.5,-2463.5 625.5,-2442.5 717.5,-2442.5 717.5,-2463.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"671.5\" y=\"-2449.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126751624&#45;&gt;140341126808128 -->\n",
       "<g id=\"edge114\" class=\"edge\">\n",
       "<title>140341126751624&#45;&gt;140341126808128</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M622.5085,-2505.7281C631.2918,-2496.2749 644.2477,-2482.3309 654.6303,-2471.1564\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"657.3966,-2473.3211 661.6393,-2463.6128 652.2684,-2468.5564 657.3966,-2473.3211\"/>\n",
       "</g>\n",
       "<!-- 140341126751736 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140341126751736</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"664.5,-2584 560.5,-2584 560.5,-2563 664.5,-2563 664.5,-2584\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-2570.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PermuteBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751736&#45;&gt;140341126751624 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140341126751736&#45;&gt;140341126751624</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M612.5,-2562.7787C612.5,-2555.6134 612.5,-2545.9517 612.5,-2537.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"616.0001,-2537.1732 612.5,-2527.1732 609.0001,-2537.1732 616.0001,-2537.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126751848 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140341126751848</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"668,-2641 557,-2641 557,-2620 668,-2620 668,-2641\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-2627.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126751848&#45;&gt;140341126751736 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140341126751848&#45;&gt;140341126751736</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M612.5,-2619.7787C612.5,-2612.6134 612.5,-2602.9517 612.5,-2594.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"616.0001,-2594.1732 612.5,-2584.1732 609.0001,-2594.1732 616.0001,-2594.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126751960 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140341126751960</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"691,-2698 534,-2698 534,-2677 691,-2677 691,-2698\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-2684.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751960&#45;&gt;140341126751848 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140341126751960&#45;&gt;140341126751848</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M612.5,-2676.7787C612.5,-2669.6134 612.5,-2659.9517 612.5,-2651.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"616.0001,-2651.1732 612.5,-2641.1732 609.0001,-2651.1732 616.0001,-2651.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126752072 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140341126752072</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"532.5,-2761.5 408.5,-2761.5 408.5,-2740.5 532.5,-2740.5 532.5,-2761.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.5\" y=\"-2747.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752072&#45;&gt;140341126751960 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140341126752072&#45;&gt;140341126751960</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M494.2676,-2740.3715C517.613,-2729.9319 553.427,-2713.9164 579.5218,-2702.2473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"580.9548,-2705.4405 588.6549,-2698.1631 578.0972,-2699.0504 580.9548,-2705.4405\"/>\n",
       "</g>\n",
       "<!-- 140341126752296 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>140341126752296</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"516.5,-2831.5 424.5,-2831.5 424.5,-2810.5 516.5,-2810.5 516.5,-2831.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.5\" y=\"-2817.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752296&#45;&gt;140341126752072 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140341126752296&#45;&gt;140341126752072</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M470.5,-2810.3685C470.5,-2800.1925 470.5,-2784.5606 470.5,-2771.8912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"474.0001,-2771.7315 470.5,-2761.7315 467.0001,-2771.7316 474.0001,-2771.7315\"/>\n",
       "</g>\n",
       "<!-- 140341126752408 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>140341126752408</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"480.5,-2895 386.5,-2895 386.5,-2874 480.5,-2874 480.5,-2895\"/>\n",
       "<text text-anchor=\"middle\" x=\"433.5\" y=\"-2881.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752408&#45;&gt;140341126752296 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>140341126752408&#45;&gt;140341126752296</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M439.7765,-2873.7281C445.0708,-2864.642 452.7824,-2851.4072 459.1551,-2840.4703\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"462.3057,-2842.0152 464.3161,-2831.6128 456.2575,-2838.491 462.3057,-2842.0152\"/>\n",
       "</g>\n",
       "<!-- 140341126752576 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>140341126752576</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"479.5,-2952 387.5,-2952 387.5,-2931 479.5,-2931 479.5,-2952\"/>\n",
       "<text text-anchor=\"middle\" x=\"433.5\" y=\"-2938.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752576&#45;&gt;140341126752408 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>140341126752576&#45;&gt;140341126752408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M433.5,-2930.7787C433.5,-2923.6134 433.5,-2913.9517 433.5,-2905.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.0001,-2905.1732 433.5,-2895.1732 430.0001,-2905.1732 437.0001,-2905.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126752688 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>140341126752688</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"471.5,-3427.5 377.5,-3427.5 377.5,-3406.5 471.5,-3406.5 471.5,-3427.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"424.5\" y=\"-3413.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126752688&#45;&gt;140341126752576 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>140341126752688&#45;&gt;140341126752576</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M427.156,-3406.4406C432.163,-3385.5772 442.5,-3337.5354 442.5,-3296.5 442.5,-3296.5 442.5,-3296.5 442.5,-3055.5 442.5,-3022.891 438.7951,-2985.1976 436.1395,-2962.3677\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"439.5811,-2961.673 434.9063,-2952.1653 432.6317,-2962.5131 439.5811,-2961.673\"/>\n",
       "</g>\n",
       "<!-- 140341126780576 -->\n",
       "<g id=\"node75\" class=\"node\">\n",
       "<title>140341126780576</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"414.5,-3364 290.5,-3364 290.5,-3343 414.5,-3343 414.5,-3364\"/>\n",
       "<text text-anchor=\"middle\" x=\"352.5\" y=\"-3350.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752688&#45;&gt;140341126780576 -->\n",
       "<g id=\"edge79\" class=\"edge\">\n",
       "<title>140341126752688&#45;&gt;140341126780576</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M412.2862,-3406.2281C401.3595,-3396.5914 385.1412,-3382.2877 372.3523,-3371.0086\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"374.3484,-3368.1024 364.5334,-3364.1128 369.7183,-3373.3523 374.3484,-3368.1024\"/>\n",
       "</g>\n",
       "<!-- 140341126752856 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>140341126752856</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"470.5,-3491 378.5,-3491 378.5,-3470 470.5,-3470 470.5,-3491\"/>\n",
       "<text text-anchor=\"middle\" x=\"424.5\" y=\"-3477.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752856&#45;&gt;140341126752688 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>140341126752856&#45;&gt;140341126752688</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M424.5,-3469.7281C424.5,-3461.0091 424.5,-3448.4699 424.5,-3437.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"428.0001,-3437.6128 424.5,-3427.6128 421.0001,-3437.6129 428.0001,-3437.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126752464 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>140341126752464</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"517.5,-3966.5 423.5,-3966.5 423.5,-3945.5 517.5,-3945.5 517.5,-3966.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.5\" y=\"-3952.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126752464&#45;&gt;140341126752296 -->\n",
       "<g id=\"edge84\" class=\"edge\">\n",
       "<title>140341126752464&#45;&gt;140341126752296</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M476.2714,-3945.3905C486.9018,-3924.8264 508.5,-3877.8359 508.5,-3835.5 508.5,-3835.5 508.5,-3835.5 508.5,-2941.5 508.5,-2904.6214 492.1112,-2864.211 480.8593,-2840.8128\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"483.8653,-2838.9976 476.2714,-2831.6095 477.6005,-2842.1206 483.8653,-2838.9976\"/>\n",
       "</g>\n",
       "<!-- 140341126752464&#45;&gt;140341126752856 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>140341126752464&#45;&gt;140341126752856</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M470.5,-3945.3613C470.5,-3924.3591 470.5,-3876.0851 470.5,-3835.5 470.5,-3835.5 470.5,-3835.5 470.5,-3594.5 470.5,-3559.177 451.2729,-3521.8778 437.6798,-3499.9221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"440.4487,-3497.7569 432.096,-3491.239 434.5611,-3501.5431 440.4487,-3497.7569\"/>\n",
       "</g>\n",
       "<!-- 140341126779848 -->\n",
       "<g id=\"node64\" class=\"node\">\n",
       "<title>140341126779848</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"442.5,-3903 318.5,-3903 318.5,-3882 442.5,-3882 442.5,-3903\"/>\n",
       "<text text-anchor=\"middle\" x=\"380.5\" y=\"-3889.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752464&#45;&gt;140341126779848 -->\n",
       "<g id=\"edge67\" class=\"edge\">\n",
       "<title>140341126752464&#45;&gt;140341126779848</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M455.2327,-3945.2281C441.1841,-3935.316 420.1376,-3920.4665 403.9558,-3909.0494\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"405.7305,-3906.0181 395.5418,-3903.1128 401.695,-3911.7378 405.7305,-3906.0181\"/>\n",
       "</g>\n",
       "<!-- 140341126753080 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>140341126753080</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"516.5,-4030 424.5,-4030 424.5,-4009 516.5,-4009 516.5,-4030\"/>\n",
       "<text text-anchor=\"middle\" x=\"470.5\" y=\"-4016.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753080&#45;&gt;140341126752464 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>140341126753080&#45;&gt;140341126752464</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M470.5,-4008.7281C470.5,-4000.0091 470.5,-3987.4699 470.5,-3976.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"474.0001,-3976.6128 470.5,-3966.6128 467.0001,-3976.6129 474.0001,-3976.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126753192 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>140341126753192</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"559.5,-4087 465.5,-4087 465.5,-4066 559.5,-4066 559.5,-4087\"/>\n",
       "<text text-anchor=\"middle\" x=\"512.5\" y=\"-4073.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753192&#45;&gt;140341126753080 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>140341126753192&#45;&gt;140341126753080</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M504.6001,-4065.7787C498.9098,-4058.0561 491.0827,-4047.4337 484.3625,-4038.3134\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"487.1142,-4036.1476 478.3645,-4030.1732 481.4788,-4040.3 487.1142,-4036.1476\"/>\n",
       "</g>\n",
       "<!-- 140341126753360 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>140341126753360</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"584,-4144 473,-4144 473,-4123 584,-4123 584,-4144\"/>\n",
       "<text text-anchor=\"middle\" x=\"528.5\" y=\"-4130.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126753360&#45;&gt;140341126753192 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>140341126753360&#45;&gt;140341126753192</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M525.4905,-4122.7787C523.4569,-4115.5338 520.7068,-4105.7367 518.2606,-4097.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"521.5684,-4095.8552 515.496,-4087.1732 514.8289,-4097.747 521.5684,-4095.8552\"/>\n",
       "</g>\n",
       "<!-- 140341126753472 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>140341126753472</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"682,-4201 525,-4201 525,-4180 682,-4180 682,-4201\"/>\n",
       "<text text-anchor=\"middle\" x=\"603.5\" y=\"-4187.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126753472&#45;&gt;140341126753360 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>140341126753472&#45;&gt;140341126753360</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M589.3931,-4179.7787C578.4984,-4171.4988 563.2177,-4159.8855 550.6896,-4150.3641\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"552.6231,-4147.4375 542.5437,-4144.1732 548.3875,-4153.0106 552.6231,-4147.4375\"/>\n",
       "</g>\n",
       "<!-- 140341126753584 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>140341126753584</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"729.5,-4264.5 605.5,-4264.5 605.5,-4243.5 729.5,-4243.5 729.5,-4264.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"667.5\" y=\"-4250.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753584&#45;&gt;140341126753472 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>140341126753584&#45;&gt;140341126753472</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M656.6433,-4243.2281C647.0232,-4233.6831 632.7885,-4219.5597 621.4721,-4208.3317\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"623.7603,-4205.6716 614.1964,-4201.1128 618.83,-4210.6407 623.7603,-4205.6716\"/>\n",
       "</g>\n",
       "<!-- 140341126753248 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>140341126753248</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"596.5,-4334.5 504.5,-4334.5 504.5,-4313.5 596.5,-4313.5 596.5,-4334.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"550.5\" y=\"-4320.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753248&#45;&gt;140341126753080 -->\n",
       "<g id=\"edge59\" class=\"edge\">\n",
       "<title>140341126753248&#45;&gt;140341126753080</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M515.678,-4313.384C494.3683,-4305.1369 468.2561,-4291.5802 452.5,-4271 430.1533,-4241.8113 433.5,-4227.2608 433.5,-4190.5 433.5,-4190.5 433.5,-4190.5 433.5,-4133.5 433.5,-4099.0351 448.9887,-4061.4461 459.9236,-4039.2031\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"463.1261,-4040.6275 464.5553,-4030.1295 456.8914,-4037.4449 463.1261,-4040.6275\"/>\n",
       "</g>\n",
       "<!-- 140341126753248&#45;&gt;140341126753584 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>140341126753248&#45;&gt;140341126753584</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M568.2698,-4313.3685C587.7099,-4301.7376 619.0631,-4282.9793 641.3199,-4269.6633\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"643.1619,-4272.6399 649.9463,-4264.5022 639.568,-4266.6329 643.1619,-4272.6399\"/>\n",
       "</g>\n",
       "<!-- 140341126753864 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>140341126753864</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"639.5,-4398 545.5,-4398 545.5,-4377 639.5,-4377 639.5,-4398\"/>\n",
       "<text text-anchor=\"middle\" x=\"592.5\" y=\"-4384.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753864&#45;&gt;140341126753248 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>140341126753864&#45;&gt;140341126753248</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M585.3753,-4376.7281C579.3049,-4367.5503 570.4347,-4354.1394 563.1593,-4343.1396\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"565.9554,-4341.0227 557.5195,-4334.6128 560.117,-4344.8843 565.9554,-4341.0227\"/>\n",
       "</g>\n",
       "<!-- 140341126754032 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>140341126754032</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"664,-4455 553,-4455 553,-4434 664,-4434 664,-4455\"/>\n",
       "<text text-anchor=\"middle\" x=\"608.5\" y=\"-4441.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126754032&#45;&gt;140341126753864 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>140341126754032&#45;&gt;140341126753864</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M605.4905,-4433.7787C603.4569,-4426.5338 600.7068,-4416.7367 598.2606,-4408.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"601.5684,-4406.8552 595.496,-4398.1732 594.8289,-4408.747 601.5684,-4406.8552\"/>\n",
       "</g>\n",
       "<!-- 140341126754144 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>140341126754144</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"762,-4512 605,-4512 605,-4491 762,-4491 762,-4512\"/>\n",
       "<text text-anchor=\"middle\" x=\"683.5\" y=\"-4498.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126754144&#45;&gt;140341126754032 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>140341126754144&#45;&gt;140341126754032</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M669.3931,-4490.7787C658.4984,-4482.4988 643.2177,-4470.8855 630.6896,-4461.3641\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"632.6231,-4458.4375 622.5437,-4455.1732 628.3875,-4464.0106 632.6231,-4458.4375\"/>\n",
       "</g>\n",
       "<!-- 140341126754256 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>140341126754256</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"809.5,-4575.5 685.5,-4575.5 685.5,-4554.5 809.5,-4554.5 809.5,-4575.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"747.5\" y=\"-4561.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126754256&#45;&gt;140341126754144 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>140341126754256&#45;&gt;140341126754144</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M736.6433,-4554.2281C727.0232,-4544.6831 712.7885,-4530.5597 701.4721,-4519.3317\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"703.7603,-4516.6716 694.1964,-4512.1128 698.83,-4521.6407 703.7603,-4516.6716\"/>\n",
       "</g>\n",
       "<!-- 140341126753920 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>140341126753920</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"677.5,-4645.5 583.5,-4645.5 583.5,-4624.5 677.5,-4624.5 677.5,-4645.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-4631.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753920&#45;&gt;140341126753248 -->\n",
       "<g id=\"edge55\" class=\"edge\">\n",
       "<title>140341126753920&#45;&gt;140341126753248</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M595.678,-4624.384C574.3683,-4616.1369 548.2561,-4602.5802 532.5,-4582 510.1533,-4552.8113 513.5,-4538.2608 513.5,-4501.5 513.5,-4501.5 513.5,-4501.5 513.5,-4444.5 513.5,-4407.7082 529.4575,-4367.2706 540.4133,-4343.8435\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"543.6681,-4345.1528 544.8805,-4334.6276 537.3691,-4342.0995 543.6681,-4345.1528\"/>\n",
       "</g>\n",
       "<!-- 140341126753920&#45;&gt;140341126754256 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>140341126753920&#45;&gt;140341126754256</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M648.2698,-4624.3685C667.7099,-4612.7376 699.0631,-4593.9793 721.3199,-4580.6633\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"723.1619,-4583.6399 729.9463,-4575.5022 719.568,-4577.6329 723.1619,-4583.6399\"/>\n",
       "</g>\n",
       "<!-- 140341126779176 -->\n",
       "<g id=\"node32\" class=\"node\">\n",
       "<title>140341126779176</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"686,-4709 575,-4709 575,-4688 686,-4688 686,-4709\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-4695.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126779176&#45;&gt;140341126753920 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>140341126779176&#45;&gt;140341126753920</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M630.5,-4687.7281C630.5,-4679.0091 630.5,-4666.4699 630.5,-4655.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"634.0001,-4655.6128 630.5,-4645.6128 627.0001,-4655.6129 634.0001,-4655.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126779288 -->\n",
       "<g id=\"node33\" class=\"node\">\n",
       "<title>140341126779288</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"709,-4766 552,-4766 552,-4745 709,-4745 709,-4766\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-4752.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126779288&#45;&gt;140341126779176 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>140341126779288&#45;&gt;140341126779176</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M630.5,-4744.7787C630.5,-4737.6134 630.5,-4727.9517 630.5,-4719.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"634.0001,-4719.1732 630.5,-4709.1732 627.0001,-4719.1732 634.0001,-4719.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126779400 -->\n",
       "<g id=\"node34\" class=\"node\">\n",
       "<title>140341126779400</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"550.5,-4829.5 426.5,-4829.5 426.5,-4808.5 550.5,-4808.5 550.5,-4829.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.5\" y=\"-4815.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126779400&#45;&gt;140341126779288 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>140341126779400&#45;&gt;140341126779288</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M512.2676,-4808.3715C535.613,-4797.9319 571.427,-4781.9164 597.5218,-4770.2473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"598.9548,-4773.4405 606.6549,-4766.1631 596.0972,-4767.0504 598.9548,-4773.4405\"/>\n",
       "</g>\n",
       "<!-- 140341126779624 -->\n",
       "<g id=\"node35\" class=\"node\">\n",
       "<title>140341126779624</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"534.5,-4899.5 442.5,-4899.5 442.5,-4878.5 534.5,-4878.5 534.5,-4899.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"488.5\" y=\"-4885.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126779624&#45;&gt;140341126779400 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>140341126779624&#45;&gt;140341126779400</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M488.5,-4878.3685C488.5,-4868.1925 488.5,-4852.5606 488.5,-4839.8912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"492.0001,-4839.7315 488.5,-4829.7315 485.0001,-4839.7316 492.0001,-4839.7315\"/>\n",
       "</g>\n",
       "<!-- 140341126779736 -->\n",
       "<g id=\"node36\" class=\"node\">\n",
       "<title>140341126779736</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"599.5,-4963 505.5,-4963 505.5,-4942 599.5,-4942 599.5,-4963\"/>\n",
       "<text text-anchor=\"middle\" x=\"552.5\" y=\"-4949.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126779736&#45;&gt;140341126779624 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>140341126779736&#45;&gt;140341126779624</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M541.6433,-4941.7281C532.0232,-4932.1831 517.7885,-4918.0597 506.4721,-4906.8317\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"508.7603,-4904.1716 499.1964,-4899.6128 503.83,-4909.1407 508.7603,-4904.1716\"/>\n",
       "</g>\n",
       "<!-- 140341126779904 -->\n",
       "<g id=\"node37\" class=\"node\">\n",
       "<title>140341126779904</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"634,-5020 523,-5020 523,-4999 634,-4999 634,-5020\"/>\n",
       "<text text-anchor=\"middle\" x=\"578.5\" y=\"-5006.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126779904&#45;&gt;140341126779736 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>140341126779904&#45;&gt;140341126779736</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M573.6096,-4998.7787C570.2323,-4991.3746 565.6391,-4981.3049 561.5996,-4972.4491\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"564.703,-4970.8189 557.3685,-4963.1732 558.3342,-4973.7239 564.703,-4970.8189\"/>\n",
       "</g>\n",
       "<!-- 140341126780016 -->\n",
       "<g id=\"node38\" class=\"node\">\n",
       "<title>140341126780016</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"700,-5077 543,-5077 543,-5056 700,-5056 700,-5077\"/>\n",
       "<text text-anchor=\"middle\" x=\"621.5\" y=\"-5063.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126780016&#45;&gt;140341126779904 -->\n",
       "<g id=\"edge37\" class=\"edge\">\n",
       "<title>140341126780016&#45;&gt;140341126779904</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M613.412,-5055.7787C607.5862,-5048.0561 599.5728,-5037.4337 592.6926,-5028.3134\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"595.3682,-5026.0485 586.5517,-5020.1732 589.78,-5030.2642 595.3682,-5026.0485\"/>\n",
       "</g>\n",
       "<!-- 140341126780128 -->\n",
       "<g id=\"node39\" class=\"node\">\n",
       "<title>140341126780128</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"747.5,-5140.5 623.5,-5140.5 623.5,-5119.5 747.5,-5119.5 747.5,-5140.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"685.5\" y=\"-5126.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126780128&#45;&gt;140341126780016 -->\n",
       "<g id=\"edge38\" class=\"edge\">\n",
       "<title>140341126780128&#45;&gt;140341126780016</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M674.6433,-5119.2281C665.0232,-5109.6831 650.7885,-5095.5597 639.4721,-5084.3317\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"641.7603,-5081.6716 632.1964,-5077.1128 636.83,-5086.6407 641.7603,-5081.6716\"/>\n",
       "</g>\n",
       "<!-- 140341126779792 -->\n",
       "<g id=\"node40\" class=\"node\">\n",
       "<title>140341126779792</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"615.5,-5210.5 521.5,-5210.5 521.5,-5189.5 615.5,-5189.5 615.5,-5210.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"568.5\" y=\"-5196.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126779792&#45;&gt;140341126779624 -->\n",
       "<g id=\"edge48\" class=\"edge\">\n",
       "<title>140341126779792&#45;&gt;140341126779624</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M533.678,-5189.384C512.3683,-5181.1369 486.2561,-5167.5802 470.5,-5147 448.1533,-5117.8113 451.5,-5103.2608 451.5,-5066.5 451.5,-5066.5 451.5,-5066.5 451.5,-5009.5 451.5,-4972.7082 467.4575,-4932.2706 478.4133,-4908.8435\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"481.6681,-4910.1528 482.8805,-4899.6276 475.3691,-4907.0995 481.6681,-4910.1528\"/>\n",
       "</g>\n",
       "<!-- 140341126779792&#45;&gt;140341126780128 -->\n",
       "<g id=\"edge39\" class=\"edge\">\n",
       "<title>140341126779792&#45;&gt;140341126780128</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M586.2698,-5189.3685C605.7099,-5177.7376 637.0631,-5158.9793 659.3199,-5145.6633\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"661.1619,-5148.6399 667.9463,-5140.5022 657.568,-5142.6329 661.1619,-5148.6399\"/>\n",
       "</g>\n",
       "<!-- 140341126780408 -->\n",
       "<g id=\"node41\" class=\"node\">\n",
       "<title>140341126780408</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"624,-5274 513,-5274 513,-5253 624,-5253 624,-5274\"/>\n",
       "<text text-anchor=\"middle\" x=\"568.5\" y=\"-5260.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126780408&#45;&gt;140341126779792 -->\n",
       "<g id=\"edge40\" class=\"edge\">\n",
       "<title>140341126780408&#45;&gt;140341126779792</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M568.5,-5252.7281C568.5,-5244.0091 568.5,-5231.4699 568.5,-5220.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"572.0001,-5220.6128 568.5,-5210.6128 565.0001,-5220.6129 572.0001,-5220.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126780520 -->\n",
       "<g id=\"node42\" class=\"node\">\n",
       "<title>140341126780520</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"647,-5331 490,-5331 490,-5310 647,-5310 647,-5331\"/>\n",
       "<text text-anchor=\"middle\" x=\"568.5\" y=\"-5317.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126780520&#45;&gt;140341126780408 -->\n",
       "<g id=\"edge41\" class=\"edge\">\n",
       "<title>140341126780520&#45;&gt;140341126780408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M568.5,-5309.7787C568.5,-5302.6134 568.5,-5292.9517 568.5,-5284.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"572.0001,-5284.1732 568.5,-5274.1732 565.0001,-5284.1732 572.0001,-5284.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126780632 -->\n",
       "<g id=\"node43\" class=\"node\">\n",
       "<title>140341126780632</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"559.5,-5394.5 435.5,-5394.5 435.5,-5373.5 559.5,-5373.5 559.5,-5394.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.5\" y=\"-5380.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126780632&#45;&gt;140341126780520 -->\n",
       "<g id=\"edge42\" class=\"edge\">\n",
       "<title>140341126780632&#45;&gt;140341126780520</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M509.5442,-5373.2281C520.3191,-5363.5914 536.3122,-5349.2877 548.9235,-5338.0086\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"551.5131,-5340.3881 556.6337,-5331.1128 546.8466,-5335.1704 551.5131,-5340.3881\"/>\n",
       "</g>\n",
       "<!-- 140341126780800 -->\n",
       "<g id=\"node44\" class=\"node\">\n",
       "<title>140341126780800</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"567.5,-5471 427.5,-5471 427.5,-5437 567.5,-5437 567.5,-5471\"/>\n",
       "<text text-anchor=\"middle\" x=\"497.5\" y=\"-5457.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"497.5\" y=\"-5444.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 1025, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126780800&#45;&gt;140341126780632 -->\n",
       "<g id=\"edge43\" class=\"edge\">\n",
       "<title>140341126780800&#45;&gt;140341126780632</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M497.5,-5436.6966C497.5,-5427.0634 497.5,-5415.003 497.5,-5404.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"501.0001,-5404.7912 497.5,-5394.7913 494.0001,-5404.7913 501.0001,-5404.7912\"/>\n",
       "</g>\n",
       "<!-- 140341126780688 -->\n",
       "<g id=\"node45\" class=\"node\">\n",
       "<title>140341126780688</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"703.5,-5401 577.5,-5401 577.5,-5367 703.5,-5367 703.5,-5401\"/>\n",
       "<text text-anchor=\"middle\" x=\"640.5\" y=\"-5387.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"640.5\" y=\"-5374.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126780688&#45;&gt;140341126780520 -->\n",
       "<g id=\"edge44\" class=\"edge\">\n",
       "<title>140341126780688&#45;&gt;140341126780520</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M621.2053,-5366.9832C611.0819,-5358.0549 598.6939,-5347.1294 588.4721,-5338.1143\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"590.6385,-5335.3582 580.8235,-5331.3687 586.0084,-5340.6082 590.6385,-5335.3582\"/>\n",
       "</g>\n",
       "<!-- 140341126780184 -->\n",
       "<g id=\"node46\" class=\"node\">\n",
       "<title>140341126780184</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"889.5,-5140.5 765.5,-5140.5 765.5,-5119.5 889.5,-5119.5 889.5,-5140.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"827.5\" y=\"-5126.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126780184&#45;&gt;140341126780016 -->\n",
       "<g id=\"edge45\" class=\"edge\">\n",
       "<title>140341126780184&#45;&gt;140341126780016</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M793.0202,-5119.3715C758.008,-5108.5789 703.6639,-5091.8272 665.5519,-5080.0791\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"666.3362,-5076.6584 655.7489,-5077.0573 664.2741,-5083.3478 666.3362,-5076.6584\"/>\n",
       "</g>\n",
       "<!-- 140341126780352 -->\n",
       "<g id=\"node47\" class=\"node\">\n",
       "<title>140341126780352</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"897.5,-5217 757.5,-5217 757.5,-5183 897.5,-5183 897.5,-5217\"/>\n",
       "<text text-anchor=\"middle\" x=\"827.5\" y=\"-5203.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"827.5\" y=\"-5190.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126780352&#45;&gt;140341126780184 -->\n",
       "<g id=\"edge46\" class=\"edge\">\n",
       "<title>140341126780352&#45;&gt;140341126780184</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M827.5,-5182.6966C827.5,-5173.0634 827.5,-5161.003 827.5,-5150.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"831.0001,-5150.7912 827.5,-5140.7913 824.0001,-5150.7913 831.0001,-5150.7912\"/>\n",
       "</g>\n",
       "<!-- 140341126780240 -->\n",
       "<g id=\"node48\" class=\"node\">\n",
       "<title>140341126780240</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"605.5,-5147 479.5,-5147 479.5,-5113 605.5,-5113 605.5,-5147\"/>\n",
       "<text text-anchor=\"middle\" x=\"542.5\" y=\"-5133.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"542.5\" y=\"-5120.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126780240&#45;&gt;140341126780016 -->\n",
       "<g id=\"edge47\" class=\"edge\">\n",
       "<title>140341126780240&#45;&gt;140341126780016</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M563.6706,-5112.9832C574.8882,-5103.9665 588.64,-5092.9128 599.9186,-5083.8471\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"602.3769,-5086.3617 607.9783,-5077.3687 597.9913,-5080.9057 602.3769,-5086.3617\"/>\n",
       "</g>\n",
       "<!-- 140341126779456 -->\n",
       "<g id=\"node49\" class=\"node\">\n",
       "<title>140341126779456</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"692.5,-4829.5 568.5,-4829.5 568.5,-4808.5 692.5,-4808.5 692.5,-4829.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-4815.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126779456&#45;&gt;140341126779288 -->\n",
       "<g id=\"edge49\" class=\"edge\">\n",
       "<title>140341126779456&#45;&gt;140341126779288</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M630.5,-4808.2281C630.5,-4799.5091 630.5,-4786.9699 630.5,-4776.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"634.0001,-4776.1128 630.5,-4766.1128 627.0001,-4776.1129 634.0001,-4776.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126779680 -->\n",
       "<g id=\"node50\" class=\"node\">\n",
       "<title>140341126779680</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"700.5,-4906 560.5,-4906 560.5,-4872 700.5,-4872 700.5,-4906\"/>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-4892.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"630.5\" y=\"-4879.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 768, 4)</text>\n",
       "</g>\n",
       "<!-- 140341126779680&#45;&gt;140341126779456 -->\n",
       "<g id=\"edge50\" class=\"edge\">\n",
       "<title>140341126779680&#45;&gt;140341126779456</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M630.5,-4871.6966C630.5,-4862.0634 630.5,-4850.003 630.5,-4839.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"634.0001,-4839.7912 630.5,-4829.7913 627.0001,-4839.7913 634.0001,-4839.7912\"/>\n",
       "</g>\n",
       "<!-- 140341126779512 -->\n",
       "<g id=\"node51\" class=\"node\">\n",
       "<title>140341126779512</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"836.5,-4836 710.5,-4836 710.5,-4802 836.5,-4802 836.5,-4836\"/>\n",
       "<text text-anchor=\"middle\" x=\"773.5\" y=\"-4822.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"773.5\" y=\"-4809.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126779512&#45;&gt;140341126779288 -->\n",
       "<g id=\"edge51\" class=\"edge\">\n",
       "<title>140341126779512&#45;&gt;140341126779288</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M735.1786,-4801.9832C712.9382,-4792.1072 685.1946,-4779.7874 663.858,-4770.3128\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"665.1083,-4767.0385 654.5484,-4766.1788 662.2673,-4773.4361 665.1083,-4767.0385\"/>\n",
       "</g>\n",
       "<!-- 140341126778952 -->\n",
       "<g id=\"node52\" class=\"node\">\n",
       "<title>140341126778952</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"951.5,-4575.5 827.5,-4575.5 827.5,-4554.5 951.5,-4554.5 951.5,-4575.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"889.5\" y=\"-4561.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126778952&#45;&gt;140341126754144 -->\n",
       "<g id=\"edge52\" class=\"edge\">\n",
       "<title>140341126778952&#45;&gt;140341126754144</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M855.0202,-4554.3715C820.008,-4543.5789 765.6639,-4526.8272 727.5519,-4515.0791\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"728.3362,-4511.6584 717.7489,-4512.0573 726.2741,-4518.3478 728.3362,-4511.6584\"/>\n",
       "</g>\n",
       "<!-- 140341126779120 -->\n",
       "<g id=\"node53\" class=\"node\">\n",
       "<title>140341126779120</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"959.5,-4652 819.5,-4652 819.5,-4618 959.5,-4618 959.5,-4652\"/>\n",
       "<text text-anchor=\"middle\" x=\"889.5\" y=\"-4638.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_4.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"889.5\" y=\"-4625.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126779120&#45;&gt;140341126778952 -->\n",
       "<g id=\"edge53\" class=\"edge\">\n",
       "<title>140341126779120&#45;&gt;140341126778952</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M889.5,-4617.6966C889.5,-4608.0634 889.5,-4596.003 889.5,-4585.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"893.0001,-4585.7912 889.5,-4575.7913 886.0001,-4585.7913 893.0001,-4585.7912\"/>\n",
       "</g>\n",
       "<!-- 140341126779008 -->\n",
       "<g id=\"node54\" class=\"node\">\n",
       "<title>140341126779008</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"667.5,-4582 541.5,-4582 541.5,-4548 667.5,-4548 667.5,-4582\"/>\n",
       "<text text-anchor=\"middle\" x=\"604.5\" y=\"-4568.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_4.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"604.5\" y=\"-4555.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126779008&#45;&gt;140341126754144 -->\n",
       "<g id=\"edge54\" class=\"edge\">\n",
       "<title>140341126779008&#45;&gt;140341126754144</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M625.6706,-4547.9832C636.8882,-4538.9665 650.64,-4527.9128 661.9186,-4518.8471\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"664.3769,-4521.3617 669.9783,-4512.3687 659.9913,-4515.9057 664.3769,-4521.3617\"/>\n",
       "</g>\n",
       "<!-- 140341126753640 -->\n",
       "<g id=\"node55\" class=\"node\">\n",
       "<title>140341126753640</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"871.5,-4264.5 747.5,-4264.5 747.5,-4243.5 871.5,-4243.5 871.5,-4264.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"809.5\" y=\"-4250.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753640&#45;&gt;140341126753472 -->\n",
       "<g id=\"edge56\" class=\"edge\">\n",
       "<title>140341126753640&#45;&gt;140341126753472</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M775.0202,-4243.3715C740.008,-4232.5789 685.6639,-4215.8272 647.5519,-4204.0791\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"648.3362,-4200.6584 637.7489,-4201.0573 646.2741,-4207.3478 648.3362,-4200.6584\"/>\n",
       "</g>\n",
       "<!-- 140341126753808 -->\n",
       "<g id=\"node56\" class=\"node\">\n",
       "<title>140341126753808</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"879.5,-4341 739.5,-4341 739.5,-4307 879.5,-4307 879.5,-4341\"/>\n",
       "<text text-anchor=\"middle\" x=\"809.5\" y=\"-4327.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_5.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"809.5\" y=\"-4314.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126753808&#45;&gt;140341126753640 -->\n",
       "<g id=\"edge57\" class=\"edge\">\n",
       "<title>140341126753808&#45;&gt;140341126753640</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M809.5,-4306.6966C809.5,-4297.0634 809.5,-4285.003 809.5,-4274.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"813.0001,-4274.7912 809.5,-4264.7913 806.0001,-4274.7913 813.0001,-4274.7912\"/>\n",
       "</g>\n",
       "<!-- 140341126753696 -->\n",
       "<g id=\"node57\" class=\"node\">\n",
       "<title>140341126753696</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"587.5,-4271 461.5,-4271 461.5,-4237 587.5,-4237 587.5,-4271\"/>\n",
       "<text text-anchor=\"middle\" x=\"524.5\" y=\"-4257.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._conv_5.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"524.5\" y=\"-4244.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126753696&#45;&gt;140341126753472 -->\n",
       "<g id=\"edge58\" class=\"edge\">\n",
       "<title>140341126753696&#45;&gt;140341126753472</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M545.6706,-4236.9832C556.8882,-4227.9665 570.64,-4216.9128 581.9186,-4207.8471\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"584.3769,-4210.3617 589.9783,-4201.3687 579.9913,-4204.9057 584.3769,-4210.3617\"/>\n",
       "</g>\n",
       "<!-- 140341126752968 -->\n",
       "<g id=\"node58\" class=\"node\">\n",
       "<title>140341126752968</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"431,-3548 320,-3548 320,-3527 431,-3527 431,-3548\"/>\n",
       "<text text-anchor=\"middle\" x=\"375.5\" y=\"-3534.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126752968&#45;&gt;140341126752856 -->\n",
       "<g id=\"edge60\" class=\"edge\">\n",
       "<title>140341126752968&#45;&gt;140341126752856</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M384.7165,-3526.7787C391.4237,-3518.9765 400.6754,-3508.2144 408.5691,-3499.0318\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"411.46,-3501.038 415.3248,-3491.1732 406.1518,-3496.4748 411.46,-3501.038\"/>\n",
       "</g>\n",
       "<!-- 140341126753136 -->\n",
       "<g id=\"node59\" class=\"node\">\n",
       "<title>140341126753136</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"442,-3605 285,-3605 285,-3584 442,-3584 442,-3605\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-3591.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126753136&#45;&gt;140341126752968 -->\n",
       "<g id=\"edge61\" class=\"edge\">\n",
       "<title>140341126753136&#45;&gt;140341126752968</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M365.7571,-3583.7787C367.2824,-3576.5338 369.3449,-3566.7367 371.1796,-3558.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"374.6178,-3558.6798 373.253,-3548.1732 367.7679,-3557.2376 374.6178,-3558.6798\"/>\n",
       "</g>\n",
       "<!-- 140341126753416 -->\n",
       "<g id=\"node60\" class=\"node\">\n",
       "<title>140341126753416</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"425.5,-3662 301.5,-3662 301.5,-3641 425.5,-3641 425.5,-3662\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-3648.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753416&#45;&gt;140341126753136 -->\n",
       "<g id=\"edge62\" class=\"edge\">\n",
       "<title>140341126753416&#45;&gt;140341126753136</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M363.5,-3640.7787C363.5,-3633.6134 363.5,-3623.9517 363.5,-3615.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.0001,-3615.1732 363.5,-3605.1732 360.0001,-3615.1732 367.0001,-3615.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126753976 -->\n",
       "<g id=\"node61\" class=\"node\">\n",
       "<title>140341126753976</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"420,-3725.5 307,-3725.5 307,-3704.5 420,-3704.5 420,-3725.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-3711.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140341126753976&#45;&gt;140341126753416 -->\n",
       "<g id=\"edge63\" class=\"edge\">\n",
       "<title>140341126753976&#45;&gt;140341126753416</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M363.5,-3704.2281C363.5,-3695.5091 363.5,-3682.9699 363.5,-3672.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.0001,-3672.1128 363.5,-3662.1128 360.0001,-3672.1129 367.0001,-3672.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126754088 -->\n",
       "<g id=\"node62\" class=\"node\">\n",
       "<title>140341126754088</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"399,-3789 328,-3789 328,-3768 399,-3768 399,-3789\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-3775.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 140341126754088&#45;&gt;140341126753976 -->\n",
       "<g id=\"edge64\" class=\"edge\">\n",
       "<title>140341126754088&#45;&gt;140341126753976</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M363.5,-3767.7281C363.5,-3759.0091 363.5,-3746.4699 363.5,-3735.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.0001,-3735.6128 363.5,-3725.6128 360.0001,-3735.6129 367.0001,-3735.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126779232 -->\n",
       "<g id=\"node63\" class=\"node\">\n",
       "<title>140341126779232</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"442,-3846 285,-3846 285,-3825 442,-3825 442,-3846\"/>\n",
       "<text text-anchor=\"middle\" x=\"363.5\" y=\"-3832.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126779232&#45;&gt;140341126754088 -->\n",
       "<g id=\"edge65\" class=\"edge\">\n",
       "<title>140341126779232&#45;&gt;140341126754088</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M363.5,-3824.7787C363.5,-3817.6134 363.5,-3807.9517 363.5,-3799.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"367.0001,-3799.1732 363.5,-3789.1732 360.0001,-3799.1732 367.0001,-3799.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126779848&#45;&gt;140341126779232 -->\n",
       "<g id=\"edge66\" class=\"edge\">\n",
       "<title>140341126779848&#45;&gt;140341126779232</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M377.3024,-3881.7787C375.1417,-3874.5338 372.2197,-3864.7367 369.6206,-3856.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"372.8954,-3854.7557 366.6832,-3846.1732 366.1873,-3856.7564 372.8954,-3854.7557\"/>\n",
       "</g>\n",
       "<!-- 140341126779344 -->\n",
       "<g id=\"node65\" class=\"node\">\n",
       "<title>140341126779344</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"300.5,-3903 176.5,-3903 176.5,-3882 300.5,-3882 300.5,-3903\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-3889.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126779344&#45;&gt;140341126779232 -->\n",
       "<g id=\"edge68\" class=\"edge\">\n",
       "<title>140341126779344&#45;&gt;140341126779232</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M261.7186,-3881.9123C281.2764,-3872.994 309.4643,-3860.1403 331.2192,-3850.2201\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"332.7592,-3853.3646 340.4058,-3846.031 329.8549,-3846.9955 332.7592,-3853.3646\"/>\n",
       "</g>\n",
       "<!-- 140341126780296 -->\n",
       "<g id=\"node66\" class=\"node\">\n",
       "<title>140341126780296</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"369,-3973 108,-3973 108,-3939 369,-3939 369,-3973\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-3959.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._residual_stack._layers.0._block.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-3946.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126780296&#45;&gt;140341126779344 -->\n",
       "<g id=\"edge69\" class=\"edge\">\n",
       "<title>140341126780296&#45;&gt;140341126779344</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M238.5,-3938.9832C238.5,-3931.1157 238.5,-3921.6973 238.5,-3913.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.0001,-3913.3686 238.5,-3903.3687 235.0001,-3913.3687 242.0001,-3913.3686\"/>\n",
       "</g>\n",
       "<!-- 140341126753528 -->\n",
       "<g id=\"node67\" class=\"node\">\n",
       "<title>140341126753528</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"252.5,-3662 128.5,-3662 128.5,-3641 252.5,-3641 252.5,-3662\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.5\" y=\"-3648.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753528&#45;&gt;140341126753136 -->\n",
       "<g id=\"edge70\" class=\"edge\">\n",
       "<title>140341126753528&#45;&gt;140341126753136</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M222.6345,-3640.9123C250.6735,-3631.674 291.529,-3618.213 322.0284,-3608.164\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"323.1351,-3611.4846 331.5376,-3605.031 320.9445,-3604.8361 323.1351,-3611.4846\"/>\n",
       "</g>\n",
       "<!-- 140341126754200 -->\n",
       "<g id=\"node68\" class=\"node\">\n",
       "<title>140341126754200</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"289,-3732 28,-3732 28,-3698 289,-3698 289,-3732\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.5\" y=\"-3718.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._residual_stack._layers.0._block.3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"158.5\" y=\"-3705.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 32, 1)</text>\n",
       "</g>\n",
       "<!-- 140341126754200&#45;&gt;140341126753528 -->\n",
       "<g id=\"edge71\" class=\"edge\">\n",
       "<title>140341126754200&#45;&gt;140341126753528</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M167.0754,-3697.9832C171.1738,-3689.8505 176.1072,-3680.0606 180.3875,-3671.567\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"183.6481,-3672.8739 185.0229,-3662.3687 177.397,-3669.7237 183.6481,-3672.8739\"/>\n",
       "</g>\n",
       "<!-- 140341126752744 -->\n",
       "<g id=\"node69\" class=\"node\">\n",
       "<title>140341126752744</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"403,-3009 292,-3009 292,-2988 403,-2988 403,-3009\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.5\" y=\"-2995.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126752744&#45;&gt;140341126752576 -->\n",
       "<g id=\"edge72\" class=\"edge\">\n",
       "<title>140341126752744&#45;&gt;140341126752576</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M363.6759,-2987.7787C376.4087,-2979.3396 394.3661,-2967.4376 408.8812,-2957.8171\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"410.9948,-2960.6152 417.3966,-2952.1732 407.1276,-2954.7805 410.9948,-2960.6152\"/>\n",
       "</g>\n",
       "<!-- 140341126752912 -->\n",
       "<g id=\"node70\" class=\"node\">\n",
       "<title>140341126752912</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"414,-3066 257,-3066 257,-3045 414,-3045 414,-3066\"/>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-3052.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126752912&#45;&gt;140341126752744 -->\n",
       "<g id=\"edge73\" class=\"edge\">\n",
       "<title>140341126752912&#45;&gt;140341126752744</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M337.7571,-3044.7787C339.2824,-3037.5338 341.3449,-3027.7367 343.1796,-3019.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"346.6178,-3019.6798 345.253,-3009.1732 339.7679,-3018.2376 346.6178,-3019.6798\"/>\n",
       "</g>\n",
       "<!-- 140341126753304 -->\n",
       "<g id=\"node71\" class=\"node\">\n",
       "<title>140341126753304</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"397.5,-3123 273.5,-3123 273.5,-3102 397.5,-3102 397.5,-3123\"/>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-3109.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753304&#45;&gt;140341126752912 -->\n",
       "<g id=\"edge74\" class=\"edge\">\n",
       "<title>140341126753304&#45;&gt;140341126752912</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M335.5,-3101.7787C335.5,-3094.6134 335.5,-3084.9517 335.5,-3076.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"339.0001,-3076.1732 335.5,-3066.1732 332.0001,-3076.1732 339.0001,-3076.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126780072 -->\n",
       "<g id=\"node72\" class=\"node\">\n",
       "<title>140341126780072</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"392,-3186.5 279,-3186.5 279,-3165.5 392,-3165.5 392,-3186.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-3172.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140341126780072&#45;&gt;140341126753304 -->\n",
       "<g id=\"edge75\" class=\"edge\">\n",
       "<title>140341126780072&#45;&gt;140341126753304</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M335.5,-3165.2281C335.5,-3156.5091 335.5,-3143.9699 335.5,-3133.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"339.0001,-3133.1128 335.5,-3123.1128 332.0001,-3133.1129 339.0001,-3133.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126779568 -->\n",
       "<g id=\"node73\" class=\"node\">\n",
       "<title>140341126779568</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"371,-3250 300,-3250 300,-3229 371,-3229 371,-3250\"/>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-3236.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 140341126779568&#45;&gt;140341126780072 -->\n",
       "<g id=\"edge76\" class=\"edge\">\n",
       "<title>140341126779568&#45;&gt;140341126780072</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M335.5,-3228.7281C335.5,-3220.0091 335.5,-3207.4699 335.5,-3196.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"339.0001,-3196.6128 335.5,-3186.6128 332.0001,-3196.6129 339.0001,-3196.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126780856 -->\n",
       "<g id=\"node74\" class=\"node\">\n",
       "<title>140341126780856</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"414,-3307 257,-3307 257,-3286 414,-3286 414,-3307\"/>\n",
       "<text text-anchor=\"middle\" x=\"335.5\" y=\"-3293.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126780856&#45;&gt;140341126779568 -->\n",
       "<g id=\"edge77\" class=\"edge\">\n",
       "<title>140341126780856&#45;&gt;140341126779568</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M335.5,-3285.7787C335.5,-3278.6134 335.5,-3268.9517 335.5,-3260.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"339.0001,-3260.1732 335.5,-3250.1732 332.0001,-3260.1732 339.0001,-3260.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126780576&#45;&gt;140341126780856 -->\n",
       "<g id=\"edge78\" class=\"edge\">\n",
       "<title>140341126780576&#45;&gt;140341126780856</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M349.3024,-3342.7787C347.1417,-3335.5338 344.2197,-3325.7367 341.6206,-3317.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"344.8954,-3315.7557 338.6832,-3307.1732 338.1873,-3317.7564 344.8954,-3315.7557\"/>\n",
       "</g>\n",
       "<!-- 140341126780968 -->\n",
       "<g id=\"node76\" class=\"node\">\n",
       "<title>140341126780968</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"272.5,-3364 148.5,-3364 148.5,-3343 272.5,-3343 272.5,-3364\"/>\n",
       "<text text-anchor=\"middle\" x=\"210.5\" y=\"-3350.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126780968&#45;&gt;140341126780856 -->\n",
       "<g id=\"edge80\" class=\"edge\">\n",
       "<title>140341126780968&#45;&gt;140341126780856</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M233.7186,-3342.9123C253.2764,-3333.994 281.4643,-3321.1403 303.2192,-3311.2201\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"304.7592,-3314.3646 312.4058,-3307.031 301.8549,-3307.9955 304.7592,-3314.3646\"/>\n",
       "</g>\n",
       "<!-- 140341126780912 -->\n",
       "<g id=\"node77\" class=\"node\">\n",
       "<title>140341126780912</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"341,-3434 80,-3434 80,-3400 341,-3400 341,-3434\"/>\n",
       "<text text-anchor=\"middle\" x=\"210.5\" y=\"-3420.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._residual_stack._layers.1._block.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"210.5\" y=\"-3407.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126780912&#45;&gt;140341126780968 -->\n",
       "<g id=\"edge81\" class=\"edge\">\n",
       "<title>140341126780912&#45;&gt;140341126780968</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M210.5,-3399.9832C210.5,-3392.1157 210.5,-3382.6973 210.5,-3374.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"214.0001,-3374.3686 210.5,-3364.3687 207.0001,-3374.3687 214.0001,-3374.3686\"/>\n",
       "</g>\n",
       "<!-- 140341126753752 -->\n",
       "<g id=\"node78\" class=\"node\">\n",
       "<title>140341126753752</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"224.5,-3123 100.5,-3123 100.5,-3102 224.5,-3102 224.5,-3123\"/>\n",
       "<text text-anchor=\"middle\" x=\"162.5\" y=\"-3109.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753752&#45;&gt;140341126752912 -->\n",
       "<g id=\"edge82\" class=\"edge\">\n",
       "<title>140341126753752&#45;&gt;140341126752912</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M194.6345,-3101.9123C222.6735,-3092.674 263.529,-3079.213 294.0284,-3069.164\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"295.1351,-3072.4846 303.5376,-3066.031 292.9445,-3065.8361 295.1351,-3072.4846\"/>\n",
       "</g>\n",
       "<!-- 140341126779960 -->\n",
       "<g id=\"node79\" class=\"node\">\n",
       "<title>140341126779960</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"261,-3193 0,-3193 0,-3159 261,-3159 261,-3193\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-3179.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_encoder._residual_stack._layers.1._block.3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-3166.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 32, 1)</text>\n",
       "</g>\n",
       "<!-- 140341126779960&#45;&gt;140341126753752 -->\n",
       "<g id=\"edge83\" class=\"edge\">\n",
       "<title>140341126779960&#45;&gt;140341126753752</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M139.0754,-3158.9832C143.1738,-3150.8505 148.1072,-3141.0606 152.3875,-3132.567\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"155.6481,-3133.8739 157.0229,-3123.3687 149.397,-3130.7237 155.6481,-3133.8739\"/>\n",
       "</g>\n",
       "<!-- 140341126752128 -->\n",
       "<g id=\"node80\" class=\"node\">\n",
       "<title>140341126752128</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"674.5,-2761.5 550.5,-2761.5 550.5,-2740.5 674.5,-2740.5 674.5,-2761.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-2747.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752128&#45;&gt;140341126751960 -->\n",
       "<g id=\"edge85\" class=\"edge\">\n",
       "<title>140341126752128&#45;&gt;140341126751960</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M612.5,-2740.2281C612.5,-2731.5091 612.5,-2718.9699 612.5,-2708.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"616.0001,-2708.1128 612.5,-2698.1128 609.0001,-2708.1129 616.0001,-2708.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126752352 -->\n",
       "<g id=\"node81\" class=\"node\">\n",
       "<title>140341126752352</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"672.5,-2838 552.5,-2838 552.5,-2804 672.5,-2804 672.5,-2838\"/>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-2824.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_pre_vq_conv.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"612.5\" y=\"-2811.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 768, 1)</text>\n",
       "</g>\n",
       "<!-- 140341126752352&#45;&gt;140341126752128 -->\n",
       "<g id=\"edge86\" class=\"edge\">\n",
       "<title>140341126752352&#45;&gt;140341126752128</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M612.5,-2803.6966C612.5,-2794.0634 612.5,-2782.003 612.5,-2771.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"616.0001,-2771.7912 612.5,-2761.7913 609.0001,-2771.7913 616.0001,-2771.7912\"/>\n",
       "</g>\n",
       "<!-- 140341126752184 -->\n",
       "<g id=\"node82\" class=\"node\">\n",
       "<title>140341126752184</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"800,-2768 693,-2768 693,-2734 800,-2734 800,-2768\"/>\n",
       "<text text-anchor=\"middle\" x=\"746.5\" y=\"-2754.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_pre_vq_conv.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"746.5\" y=\"-2741.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n",
       "</g>\n",
       "<!-- 140341126752184&#45;&gt;140341126751960 -->\n",
       "<g id=\"edge87\" class=\"edge\">\n",
       "<title>140341126752184&#45;&gt;140341126751960</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M710.5905,-2733.9832C689.9375,-2724.1961 664.2202,-2712.0092 644.3004,-2702.5696\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"645.5704,-2699.2983 635.0348,-2698.1788 642.5727,-2705.624 645.5704,-2699.2983\"/>\n",
       "</g>\n",
       "<!-- 140341126750840 -->\n",
       "<g id=\"node83\" class=\"node\">\n",
       "<title>140341126750840</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"1222,-21 1133,-21 1133,0 1222,0 1222,-21\"/>\n",
       "<text text-anchor=\"middle\" x=\"1177.5\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751008 -->\n",
       "<g id=\"node84\" class=\"node\">\n",
       "<title>140341126751008</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1222,-78 1133,-78 1133,-57 1222,-57 1222,-78\"/>\n",
       "<text text-anchor=\"middle\" x=\"1177.5\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751008&#45;&gt;140341126750840 -->\n",
       "<g id=\"edge88\" class=\"edge\">\n",
       "<title>140341126751008&#45;&gt;140341126750840</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1177.5,-56.7787C1177.5,-49.6134 1177.5,-39.9517 1177.5,-31.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.0001,-31.1732 1177.5,-21.1732 1174.0001,-31.1732 1181.0001,-31.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126751456 -->\n",
       "<g id=\"node85\" class=\"node\">\n",
       "<title>140341126751456</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1222,-135 1133,-135 1133,-114 1222,-114 1222,-135\"/>\n",
       "<text text-anchor=\"middle\" x=\"1177.5\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SliceBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751456&#45;&gt;140341126751008 -->\n",
       "<g id=\"edge89\" class=\"edge\">\n",
       "<title>140341126751456&#45;&gt;140341126751008</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1177.5,-113.7787C1177.5,-106.6134 1177.5,-96.9517 1177.5,-88.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.0001,-88.1732 1177.5,-78.1732 1174.0001,-88.1732 1181.0001,-88.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126751680 -->\n",
       "<g id=\"node86\" class=\"node\">\n",
       "<title>140341126751680</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1223.5,-192 1131.5,-192 1131.5,-171 1223.5,-171 1223.5,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"1177.5\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n",
       "</g>\n",
       "<!-- 140341126751680&#45;&gt;140341126751456 -->\n",
       "<g id=\"edge90\" class=\"edge\">\n",
       "<title>140341126751680&#45;&gt;140341126751456</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1177.5,-170.7787C1177.5,-163.6134 1177.5,-153.9517 1177.5,-145.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.0001,-145.1732 1177.5,-135.1732 1174.0001,-145.1732 1181.0001,-145.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126751904 -->\n",
       "<g id=\"node87\" class=\"node\">\n",
       "<title>140341126751904</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1233,-249 1122,-249 1122,-228 1233,-228 1233,-249\"/>\n",
       "<text text-anchor=\"middle\" x=\"1177.5\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126751904&#45;&gt;140341126751680 -->\n",
       "<g id=\"edge91\" class=\"edge\">\n",
       "<title>140341126751904&#45;&gt;140341126751680</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1177.5,-227.7787C1177.5,-220.6134 1177.5,-210.9517 1177.5,-202.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.0001,-202.1732 1177.5,-192.1732 1174.0001,-202.1732 1181.0001,-202.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126752240 -->\n",
       "<g id=\"node88\" class=\"node\">\n",
       "<title>140341126752240</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1280.5,-306 1074.5,-306 1074.5,-285 1280.5,-285 1280.5,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"1177.5\" y=\"-292.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionTransposeBackward</text>\n",
       "</g>\n",
       "<!-- 140341126752240&#45;&gt;140341126751904 -->\n",
       "<g id=\"edge92\" class=\"edge\">\n",
       "<title>140341126752240&#45;&gt;140341126751904</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1177.5,-284.7787C1177.5,-277.6134 1177.5,-267.9517 1177.5,-259.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.0001,-259.1732 1177.5,-249.1732 1174.0001,-259.1732 1181.0001,-259.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126752800 -->\n",
       "<g id=\"node89\" class=\"node\">\n",
       "<title>140341126752800</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1095.5,-369.5 971.5,-369.5 971.5,-348.5 1095.5,-348.5 1095.5,-369.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1033.5\" y=\"-355.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126752800&#45;&gt;140341126752240 -->\n",
       "<g id=\"edge93\" class=\"edge\">\n",
       "<title>140341126752800&#45;&gt;140341126752240</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1057.6024,-348.3715C1081.2766,-337.9319 1117.595,-321.9164 1144.0573,-310.2473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1145.5813,-313.4005 1153.319,-306.1631 1142.7569,-306.9956 1145.5813,-313.4005\"/>\n",
       "</g>\n",
       "<!-- 140341126780744 -->\n",
       "<g id=\"node90\" class=\"node\">\n",
       "<title>140341126780744</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1077.5,-439.5 983.5,-439.5 983.5,-418.5 1077.5,-418.5 1077.5,-439.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1030.5\" y=\"-425.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126780744&#45;&gt;140341126752800 -->\n",
       "<g id=\"edge94\" class=\"edge\">\n",
       "<title>140341126780744&#45;&gt;140341126752800</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1030.9556,-418.3685C1031.3917,-408.1925 1032.0617,-392.5606 1032.6047,-379.8912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1036.1086,-379.8723 1033.0401,-369.7315 1029.115,-379.5725 1036.1086,-379.8723\"/>\n",
       "</g>\n",
       "<!-- 140341126781080 -->\n",
       "<g id=\"node91\" class=\"node\">\n",
       "<title>140341126781080</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1086,-503 975,-503 975,-482 1086,-482 1086,-503\"/>\n",
       "<text text-anchor=\"middle\" x=\"1030.5\" y=\"-489.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126781080&#45;&gt;140341126780744 -->\n",
       "<g id=\"edge95\" class=\"edge\">\n",
       "<title>140341126781080&#45;&gt;140341126780744</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1030.5,-481.7281C1030.5,-473.0091 1030.5,-460.4699 1030.5,-449.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1034.0001,-449.6128 1030.5,-439.6128 1027.0001,-449.6129 1034.0001,-449.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126781192 -->\n",
       "<g id=\"node92\" class=\"node\">\n",
       "<title>140341126781192</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1133.5,-560 927.5,-560 927.5,-539 1133.5,-539 1133.5,-560\"/>\n",
       "<text text-anchor=\"middle\" x=\"1030.5\" y=\"-546.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionTransposeBackward</text>\n",
       "</g>\n",
       "<!-- 140341126781192&#45;&gt;140341126781080 -->\n",
       "<g id=\"edge96\" class=\"edge\">\n",
       "<title>140341126781192&#45;&gt;140341126781080</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1030.5,-538.7787C1030.5,-531.6134 1030.5,-521.9517 1030.5,-513.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1034.0001,-513.1732 1030.5,-503.1732 1027.0001,-513.1732 1034.0001,-513.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126781136 -->\n",
       "<g id=\"node93\" class=\"node\">\n",
       "<title>140341126781136</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"948.5,-623.5 824.5,-623.5 824.5,-602.5 948.5,-602.5 948.5,-623.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"886.5\" y=\"-609.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126781136&#45;&gt;140341126781192 -->\n",
       "<g id=\"edge97\" class=\"edge\">\n",
       "<title>140341126781136&#45;&gt;140341126781192</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M910.6024,-602.3715C934.2766,-591.9319 970.595,-575.9164 997.0573,-564.2473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"998.5813,-567.4005 1006.319,-560.1631 995.7569,-560.9956 998.5813,-567.4005\"/>\n",
       "</g>\n",
       "<!-- 140341126781472 -->\n",
       "<g id=\"node94\" class=\"node\">\n",
       "<title>140341126781472</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"930.5,-693.5 836.5,-693.5 836.5,-672.5 930.5,-672.5 930.5,-693.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.5\" y=\"-679.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126781472&#45;&gt;140341126781136 -->\n",
       "<g id=\"edge98\" class=\"edge\">\n",
       "<title>140341126781472&#45;&gt;140341126781136</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M883.9556,-672.3685C884.3917,-662.1925 885.0617,-646.5606 885.6047,-633.8912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"889.1086,-633.8723 886.0401,-623.7315 882.115,-633.5725 889.1086,-633.8723\"/>\n",
       "</g>\n",
       "<!-- 140341126781584 -->\n",
       "<g id=\"node95\" class=\"node\">\n",
       "<title>140341126781584</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"939,-757 828,-757 828,-736 939,-736 939,-757\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.5\" y=\"-743.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126781584&#45;&gt;140341126781472 -->\n",
       "<g id=\"edge99\" class=\"edge\">\n",
       "<title>140341126781584&#45;&gt;140341126781472</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M883.5,-735.7281C883.5,-727.0091 883.5,-714.4699 883.5,-703.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"887.0001,-703.6128 883.5,-693.6128 880.0001,-703.6129 887.0001,-703.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126781696 -->\n",
       "<g id=\"node96\" class=\"node\">\n",
       "<title>140341126781696</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"986.5,-814 780.5,-814 780.5,-793 986.5,-793 986.5,-814\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.5\" y=\"-800.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionTransposeBackward</text>\n",
       "</g>\n",
       "<!-- 140341126781696&#45;&gt;140341126781584 -->\n",
       "<g id=\"edge100\" class=\"edge\">\n",
       "<title>140341126781696&#45;&gt;140341126781584</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M883.5,-792.7787C883.5,-785.6134 883.5,-775.9517 883.5,-767.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"887.0001,-767.1732 883.5,-757.1732 880.0001,-767.1732 887.0001,-767.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126781808 -->\n",
       "<g id=\"node97\" class=\"node\">\n",
       "<title>140341126781808</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"801.5,-877.5 677.5,-877.5 677.5,-856.5 801.5,-856.5 801.5,-877.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"739.5\" y=\"-863.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126781808&#45;&gt;140341126781696 -->\n",
       "<g id=\"edge101\" class=\"edge\">\n",
       "<title>140341126781808&#45;&gt;140341126781696</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M763.6024,-856.3715C787.2766,-845.9319 823.595,-829.9164 850.0573,-818.2473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"851.5813,-821.4005 859.319,-814.1631 848.7569,-814.9956 851.5813,-821.4005\"/>\n",
       "</g>\n",
       "<!-- 140341126782032 -->\n",
       "<g id=\"node98\" class=\"node\">\n",
       "<title>140341126782032</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"783.5,-947.5 689.5,-947.5 689.5,-926.5 783.5,-926.5 783.5,-947.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"736.5\" y=\"-933.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126782032&#45;&gt;140341126781808 -->\n",
       "<g id=\"edge102\" class=\"edge\">\n",
       "<title>140341126782032&#45;&gt;140341126781808</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M736.9556,-926.3685C737.3917,-916.1925 738.0617,-900.5606 738.6047,-887.8912\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"742.1086,-887.8723 739.0401,-877.7315 735.115,-887.5725 742.1086,-887.8723\"/>\n",
       "</g>\n",
       "<!-- 140341126782144 -->\n",
       "<g id=\"node99\" class=\"node\">\n",
       "<title>140341126782144</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"782.5,-1011 690.5,-1011 690.5,-990 782.5,-990 782.5,-1011\"/>\n",
       "<text text-anchor=\"middle\" x=\"736.5\" y=\"-997.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126782144&#45;&gt;140341126782032 -->\n",
       "<g id=\"edge103\" class=\"edge\">\n",
       "<title>140341126782144&#45;&gt;140341126782032</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M736.5,-989.7281C736.5,-981.0091 736.5,-968.4699 736.5,-957.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"740.0001,-957.6128 736.5,-947.6128 733.0001,-957.6129 740.0001,-957.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126782256 -->\n",
       "<g id=\"node100\" class=\"node\">\n",
       "<title>140341126782256</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"759.5,-1486.5 665.5,-1486.5 665.5,-1465.5 759.5,-1465.5 759.5,-1486.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"712.5\" y=\"-1472.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126782256&#45;&gt;140341126782144 -->\n",
       "<g id=\"edge104\" class=\"edge\">\n",
       "<title>140341126782256&#45;&gt;140341126782144</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M709.844,-1465.4406C704.837,-1444.5772 694.5,-1396.5354 694.5,-1355.5 694.5,-1355.5 694.5,-1355.5 694.5,-1114.5 694.5,-1079.4071 712.2405,-1041.7764 724.6618,-1019.7296\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"727.7255,-1021.4238 729.752,-1011.0246 721.6828,-1017.8903 727.7255,-1021.4238\"/>\n",
       "</g>\n",
       "<!-- 140341126808968 -->\n",
       "<g id=\"node130\" class=\"node\">\n",
       "<title>140341126808968</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"912.5,-1423 788.5,-1423 788.5,-1402 912.5,-1402 912.5,-1423\"/>\n",
       "<text text-anchor=\"middle\" x=\"850.5\" y=\"-1409.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126782256&#45;&gt;140341126808968 -->\n",
       "<g id=\"edge137\" class=\"edge\">\n",
       "<title>140341126782256&#45;&gt;140341126808968</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M735.5981,-1465.3715C758.1864,-1454.9776 792.786,-1439.0568 818.1166,-1427.4011\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"819.7052,-1430.5229 827.3265,-1423.1631 816.7791,-1424.1638 819.7052,-1430.5229\"/>\n",
       "</g>\n",
       "<!-- 140341126782424 -->\n",
       "<g id=\"node101\" class=\"node\">\n",
       "<title>140341126782424</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"758.5,-1550 666.5,-1550 666.5,-1529 758.5,-1529 758.5,-1550\"/>\n",
       "<text text-anchor=\"middle\" x=\"712.5\" y=\"-1536.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126782424&#45;&gt;140341126782256 -->\n",
       "<g id=\"edge105\" class=\"edge\">\n",
       "<title>140341126782424&#45;&gt;140341126782256</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M712.5,-1528.7281C712.5,-1520.0091 712.5,-1507.4699 712.5,-1496.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"716.0001,-1496.6128 712.5,-1486.6128 709.0001,-1496.6129 716.0001,-1496.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126782536 -->\n",
       "<g id=\"node102\" class=\"node\">\n",
       "<title>140341126782536</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"834.5,-2025.5 740.5,-2025.5 740.5,-2004.5 834.5,-2004.5 834.5,-2025.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"787.5\" y=\"-2011.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126782536&#45;&gt;140341126782424 -->\n",
       "<g id=\"edge106\" class=\"edge\">\n",
       "<title>140341126782536&#45;&gt;140341126782424</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M764.9412,-2004.4984C730.9424,-1986.9301 670.5,-1948.1526 670.5,-1894.5 670.5,-1894.5 670.5,-1894.5 670.5,-1653.5 670.5,-1618.4071 688.2405,-1580.7764 700.6618,-1558.7296\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"703.7255,-1560.4238 705.752,-1550.0246 697.6828,-1556.8903 703.7255,-1560.4238\"/>\n",
       "</g>\n",
       "<!-- 140341126808520 -->\n",
       "<g id=\"node119\" class=\"node\">\n",
       "<title>140341126808520</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"888.5,-1962 764.5,-1962 764.5,-1941 888.5,-1941 888.5,-1962\"/>\n",
       "<text text-anchor=\"middle\" x=\"826.5\" y=\"-1948.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126782536&#45;&gt;140341126808520 -->\n",
       "<g id=\"edge125\" class=\"edge\">\n",
       "<title>140341126782536&#45;&gt;140341126808520</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M794.1158,-2004.2281C799.7526,-1995.0503 807.9892,-1981.6394 814.7449,-1970.6396\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"817.7308,-1972.4658 819.9819,-1962.1128 811.7659,-1968.8023 817.7308,-1972.4658\"/>\n",
       "</g>\n",
       "<!-- 140341126782704 -->\n",
       "<g id=\"node103\" class=\"node\">\n",
       "<title>140341126782704</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"869.5,-2089 705.5,-2089 705.5,-2068 869.5,-2068 869.5,-2089\"/>\n",
       "<text text-anchor=\"middle\" x=\"787.5\" y=\"-2075.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UpsampleNearest1DBackward</text>\n",
       "</g>\n",
       "<!-- 140341126782704&#45;&gt;140341126782536 -->\n",
       "<g id=\"edge107\" class=\"edge\">\n",
       "<title>140341126782704&#45;&gt;140341126782536</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M787.5,-2067.7281C787.5,-2059.0091 787.5,-2046.4699 787.5,-2035.8068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"791.0001,-2035.6128 787.5,-2025.6128 784.0001,-2035.6129 791.0001,-2035.6128\"/>\n",
       "</g>\n",
       "<!-- 140341126782816 -->\n",
       "<g id=\"node104\" class=\"node\">\n",
       "<title>140341126782816</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"843,-2146 732,-2146 732,-2125 843,-2125 843,-2146\"/>\n",
       "<text text-anchor=\"middle\" x=\"787.5\" y=\"-2132.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126782816&#45;&gt;140341126782704 -->\n",
       "<g id=\"edge108\" class=\"edge\">\n",
       "<title>140341126782816&#45;&gt;140341126782704</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M787.5,-2124.7787C787.5,-2117.6134 787.5,-2107.9517 787.5,-2099.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"791.0001,-2099.1732 787.5,-2089.1732 784.0001,-2099.1732 791.0001,-2099.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126782928 -->\n",
       "<g id=\"node105\" class=\"node\">\n",
       "<title>140341126782928</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"866,-2203 709,-2203 709,-2182 866,-2182 866,-2203\"/>\n",
       "<text text-anchor=\"middle\" x=\"787.5\" y=\"-2189.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126782928&#45;&gt;140341126782816 -->\n",
       "<g id=\"edge109\" class=\"edge\">\n",
       "<title>140341126782928&#45;&gt;140341126782816</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M787.5,-2181.7787C787.5,-2174.6134 787.5,-2164.9517 787.5,-2156.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"791.0001,-2156.1732 787.5,-2146.1732 784.0001,-2156.1732 791.0001,-2156.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126807680 -->\n",
       "<g id=\"node106\" class=\"node\">\n",
       "<title>140341126807680</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"849.5,-2266.5 725.5,-2266.5 725.5,-2245.5 849.5,-2245.5 849.5,-2266.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"787.5\" y=\"-2252.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126807680&#45;&gt;140341126782928 -->\n",
       "<g id=\"edge110\" class=\"edge\">\n",
       "<title>140341126807680&#45;&gt;140341126782928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M787.5,-2245.2281C787.5,-2236.5091 787.5,-2223.9699 787.5,-2213.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"791.0001,-2213.1128 787.5,-2203.1128 784.0001,-2213.1129 791.0001,-2213.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126807904 -->\n",
       "<g id=\"node107\" class=\"node\">\n",
       "<title>140341126807904</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"766.5,-2336.5 670.5,-2336.5 670.5,-2315.5 766.5,-2315.5 766.5,-2336.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"718.5\" y=\"-2322.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CopyBackwards</text>\n",
       "</g>\n",
       "<!-- 140341126807904&#45;&gt;140341126807680 -->\n",
       "<g id=\"edge111\" class=\"edge\">\n",
       "<title>140341126807904&#45;&gt;140341126807680</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M728.9796,-2315.3685C739.8208,-2304.3702 756.9442,-2286.9987 769.8732,-2273.8822\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"772.3943,-2276.3103 776.9218,-2266.7315 767.4091,-2271.3963 772.3943,-2276.3103\"/>\n",
       "</g>\n",
       "<!-- 140341126808016 -->\n",
       "<g id=\"node108\" class=\"node\">\n",
       "<title>140341126808016</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"737.5,-2400 633.5,-2400 633.5,-2379 737.5,-2379 737.5,-2400\"/>\n",
       "<text text-anchor=\"middle\" x=\"685.5\" y=\"-2386.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PermuteBackward</text>\n",
       "</g>\n",
       "<!-- 140341126808016&#45;&gt;140341126807904 -->\n",
       "<g id=\"edge112\" class=\"edge\">\n",
       "<title>140341126808016&#45;&gt;140341126807904</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M691.098,-2378.7281C695.7722,-2369.7338 702.5591,-2356.6741 708.209,-2345.8025\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"711.479,-2347.1001 712.9847,-2336.6128 705.2676,-2343.8722 711.479,-2347.1001\"/>\n",
       "</g>\n",
       "<!-- 140341126808128&#45;&gt;140341126808016 -->\n",
       "<g id=\"edge113\" class=\"edge\">\n",
       "<title>140341126808128&#45;&gt;140341126808016</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M673.8749,-2442.2281C675.8174,-2433.4174 678.6201,-2420.7055 680.9868,-2409.9708\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"684.425,-2410.6319 683.1602,-2400.1128 677.5892,-2409.1247 684.425,-2410.6319\"/>\n",
       "</g>\n",
       "<!-- 140341126807736 -->\n",
       "<g id=\"node110\" class=\"node\">\n",
       "<title>140341126807736</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"991.5,-2266.5 867.5,-2266.5 867.5,-2245.5 991.5,-2245.5 991.5,-2266.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"929.5\" y=\"-2252.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126807736&#45;&gt;140341126782928 -->\n",
       "<g id=\"edge115\" class=\"edge\">\n",
       "<title>140341126807736&#45;&gt;140341126782928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M905.7324,-2245.3715C882.387,-2234.9319 846.573,-2218.9164 820.4782,-2207.2473\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"821.9028,-2204.0504 811.3451,-2203.1631 819.0452,-2210.4405 821.9028,-2204.0504\"/>\n",
       "</g>\n",
       "<!-- 140341126807960 -->\n",
       "<g id=\"node111\" class=\"node\">\n",
       "<title>140341126807960</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"999.5,-2343 859.5,-2343 859.5,-2309 999.5,-2309 999.5,-2343\"/>\n",
       "<text text-anchor=\"middle\" x=\"929.5\" y=\"-2329.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"929.5\" y=\"-2316.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 64, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126807960&#45;&gt;140341126807736 -->\n",
       "<g id=\"edge116\" class=\"edge\">\n",
       "<title>140341126807960&#45;&gt;140341126807736</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M929.5,-2308.6966C929.5,-2299.0634 929.5,-2287.003 929.5,-2276.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"933.0001,-2276.7912 929.5,-2266.7913 926.0001,-2276.7913 933.0001,-2276.7912\"/>\n",
       "</g>\n",
       "<!-- 140341126807792 -->\n",
       "<g id=\"node112\" class=\"node\">\n",
       "<title>140341126807792</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"707.5,-2273 581.5,-2273 581.5,-2239 707.5,-2239 707.5,-2273\"/>\n",
       "<text text-anchor=\"middle\" x=\"644.5\" y=\"-2259.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"644.5\" y=\"-2246.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126807792&#45;&gt;140341126782928 -->\n",
       "<g id=\"edge117\" class=\"edge\">\n",
       "<title>140341126807792&#45;&gt;140341126782928</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M682.8214,-2238.9832C705.0618,-2229.1072 732.8054,-2216.7874 754.142,-2207.3128\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"755.7327,-2210.4361 763.4516,-2203.1788 752.8917,-2204.0385 755.7327,-2210.4361\"/>\n",
       "</g>\n",
       "<!-- 140341126782592 -->\n",
       "<g id=\"node113\" class=\"node\">\n",
       "<title>140341126782592</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"847,-1607 736,-1607 736,-1586 847,-1586 847,-1607\"/>\n",
       "<text text-anchor=\"middle\" x=\"791.5\" y=\"-1593.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126782592&#45;&gt;140341126782424 -->\n",
       "<g id=\"edge118\" class=\"edge\">\n",
       "<title>140341126782592&#45;&gt;140341126782424</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M776.6407,-1585.7787C765.0547,-1577.4192 748.7594,-1565.6618 735.4931,-1556.09\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"737.4501,-1553.1861 727.2927,-1550.1732 733.3543,-1558.8627 737.4501,-1553.1861\"/>\n",
       "</g>\n",
       "<!-- 140341126782760 -->\n",
       "<g id=\"node114\" class=\"node\">\n",
       "<title>140341126782760</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"908,-1664 751,-1664 751,-1643 908,-1643 908,-1664\"/>\n",
       "<text text-anchor=\"middle\" x=\"829.5\" y=\"-1650.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126782760&#45;&gt;140341126782592 -->\n",
       "<g id=\"edge119\" class=\"edge\">\n",
       "<title>140341126782760&#45;&gt;140341126782592</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M822.3525,-1642.7787C817.2571,-1635.1357 810.2683,-1624.6524 804.2306,-1615.596\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"807.0747,-1613.5522 798.6155,-1607.1732 801.2503,-1617.4352 807.0747,-1613.5522\"/>\n",
       "</g>\n",
       "<!-- 140341126807624 -->\n",
       "<g id=\"node115\" class=\"node\">\n",
       "<title>140341126807624</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1064.5,-1721 940.5,-1721 940.5,-1700 1064.5,-1700 1064.5,-1721\"/>\n",
       "<text text-anchor=\"middle\" x=\"1002.5\" y=\"-1707.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126807624&#45;&gt;140341126782760 -->\n",
       "<g id=\"edge120\" class=\"edge\">\n",
       "<title>140341126807624&#45;&gt;140341126782760</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M970.3655,-1699.9123C942.3265,-1690.674 901.471,-1677.213 870.9716,-1667.164\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"872.0555,-1663.8361 861.4624,-1664.031 869.8649,-1670.4846 872.0555,-1663.8361\"/>\n",
       "</g>\n",
       "<!-- 140341126808240 -->\n",
       "<g id=\"node116\" class=\"node\">\n",
       "<title>140341126808240</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1091,-1784.5 978,-1784.5 978,-1763.5 1091,-1763.5 1091,-1784.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1034.5\" y=\"-1770.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140341126808240&#45;&gt;140341126807624 -->\n",
       "<g id=\"edge121\" class=\"edge\">\n",
       "<title>140341126808240&#45;&gt;140341126807624</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1029.0716,-1763.2281C1024.5391,-1754.2338 1017.9578,-1741.1741 1012.4792,-1730.3025\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1015.4741,-1728.4679 1007.8482,-1721.1128 1009.2229,-1731.6181 1015.4741,-1728.4679\"/>\n",
       "</g>\n",
       "<!-- 140341126808184 -->\n",
       "<g id=\"node117\" class=\"node\">\n",
       "<title>140341126808184</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1053,-1848 982,-1848 982,-1827 1053,-1827 1053,-1848\"/>\n",
       "<text text-anchor=\"middle\" x=\"1017.5\" y=\"-1834.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 140341126808184&#45;&gt;140341126808240 -->\n",
       "<g id=\"edge122\" class=\"edge\">\n",
       "<title>140341126808184&#45;&gt;140341126808240</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1020.3838,-1826.7281C1022.7426,-1817.9174 1026.1458,-1805.2055 1029.0196,-1794.4708\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1032.4535,-1795.1778 1031.6588,-1784.6128 1025.6917,-1793.3675 1032.4535,-1795.1778\"/>\n",
       "</g>\n",
       "<!-- 140341126808408 -->\n",
       "<g id=\"node118\" class=\"node\">\n",
       "<title>140341126808408</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1080,-1905 923,-1905 923,-1884 1080,-1884 1080,-1905\"/>\n",
       "<text text-anchor=\"middle\" x=\"1001.5\" y=\"-1891.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126808408&#45;&gt;140341126808184 -->\n",
       "<g id=\"edge123\" class=\"edge\">\n",
       "<title>140341126808408&#45;&gt;140341126808184</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1004.5095,-1883.7787C1006.5431,-1876.5338 1009.2932,-1866.7367 1011.7394,-1858.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1015.1711,-1858.747 1014.504,-1848.1732 1008.4316,-1856.8552 1015.1711,-1858.747\"/>\n",
       "</g>\n",
       "<!-- 140341126808520&#45;&gt;140341126808408 -->\n",
       "<g id=\"edge124\" class=\"edge\">\n",
       "<title>140341126808520&#45;&gt;140341126808408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M859.006,-1940.9123C887.3692,-1931.674 928.697,-1918.213 959.549,-1908.164\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"960.7437,-1911.456 969.1681,-1905.031 958.5757,-1904.8001 960.7437,-1911.456\"/>\n",
       "</g>\n",
       "<!-- 140341126808576 -->\n",
       "<g id=\"node120\" class=\"node\">\n",
       "<title>140341126808576</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1063.5,-1962 939.5,-1962 939.5,-1941 1063.5,-1941 1063.5,-1962\"/>\n",
       "<text text-anchor=\"middle\" x=\"1001.5\" y=\"-1948.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126808576&#45;&gt;140341126808408 -->\n",
       "<g id=\"edge126\" class=\"edge\">\n",
       "<title>140341126808576&#45;&gt;140341126808408</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1001.5,-1940.7787C1001.5,-1933.6134 1001.5,-1923.9517 1001.5,-1915.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1005.0001,-1915.1732 1001.5,-1905.1732 998.0001,-1915.1732 1005.0001,-1915.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126808688 -->\n",
       "<g id=\"node121\" class=\"node\">\n",
       "<title>140341126808688</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1132,-2032 871,-2032 871,-1998 1132,-1998 1132,-2032\"/>\n",
       "<text text-anchor=\"middle\" x=\"1001.5\" y=\"-2018.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._residual_stack._layers.0._block.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1001.5\" y=\"-2005.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126808688&#45;&gt;140341126808576 -->\n",
       "<g id=\"edge127\" class=\"edge\">\n",
       "<title>140341126808688&#45;&gt;140341126808576</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1001.5,-1997.9832C1001.5,-1990.1157 1001.5,-1980.6973 1001.5,-1972.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1005.0001,-1972.3686 1001.5,-1962.3687 998.0001,-1972.3687 1005.0001,-1972.3686\"/>\n",
       "</g>\n",
       "<!-- 140341126807848 -->\n",
       "<g id=\"node122\" class=\"node\">\n",
       "<title>140341126807848</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"891.5,-1721 767.5,-1721 767.5,-1700 891.5,-1700 891.5,-1721\"/>\n",
       "<text text-anchor=\"middle\" x=\"829.5\" y=\"-1707.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126807848&#45;&gt;140341126782760 -->\n",
       "<g id=\"edge128\" class=\"edge\">\n",
       "<title>140341126807848&#45;&gt;140341126782760</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M829.5,-1699.7787C829.5,-1692.6134 829.5,-1682.9517 829.5,-1674.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"833.0001,-1674.1732 829.5,-1664.1732 826.0001,-1674.1732 833.0001,-1674.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126808296 -->\n",
       "<g id=\"node123\" class=\"node\">\n",
       "<title>140341126808296</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"960,-1791 699,-1791 699,-1757 960,-1757 960,-1791\"/>\n",
       "<text text-anchor=\"middle\" x=\"829.5\" y=\"-1777.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._residual_stack._layers.0._block.3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"829.5\" y=\"-1764.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 32, 1)</text>\n",
       "</g>\n",
       "<!-- 140341126808296&#45;&gt;140341126807848 -->\n",
       "<g id=\"edge129\" class=\"edge\">\n",
       "<title>140341126808296&#45;&gt;140341126807848</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M829.5,-1756.9832C829.5,-1749.1157 829.5,-1739.6973 829.5,-1731.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"833.0001,-1731.3686 829.5,-1721.3687 826.0001,-1731.3687 833.0001,-1731.3686\"/>\n",
       "</g>\n",
       "<!-- 140341126782312 -->\n",
       "<g id=\"node124\" class=\"node\">\n",
       "<title>140341126782312</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"871,-1068 760,-1068 760,-1047 871,-1047 871,-1068\"/>\n",
       "<text text-anchor=\"middle\" x=\"815.5\" y=\"-1054.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SqueezeBackward1</text>\n",
       "</g>\n",
       "<!-- 140341126782312&#45;&gt;140341126782144 -->\n",
       "<g id=\"edge130\" class=\"edge\">\n",
       "<title>140341126782312&#45;&gt;140341126782144</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M800.6407,-1046.7787C789.0547,-1038.4192 772.7594,-1026.6618 759.4931,-1017.09\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"761.4501,-1014.1861 751.2927,-1011.1732 757.3543,-1019.8627 761.4501,-1014.1861\"/>\n",
       "</g>\n",
       "<!-- 140341126782480 -->\n",
       "<g id=\"node125\" class=\"node\">\n",
       "<title>140341126782480</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"932,-1125 775,-1125 775,-1104 932,-1104 932,-1125\"/>\n",
       "<text text-anchor=\"middle\" x=\"853.5\" y=\"-1111.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126782480&#45;&gt;140341126782312 -->\n",
       "<g id=\"edge131\" class=\"edge\">\n",
       "<title>140341126782480&#45;&gt;140341126782312</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M846.3525,-1103.7787C841.2571,-1096.1357 834.2683,-1085.6524 828.2306,-1076.596\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"831.0747,-1074.5522 822.6155,-1068.1732 825.2503,-1078.4352 831.0747,-1074.5522\"/>\n",
       "</g>\n",
       "<!-- 140341126782872 -->\n",
       "<g id=\"node126\" class=\"node\">\n",
       "<title>140341126782872</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1088.5,-1182 964.5,-1182 964.5,-1161 1088.5,-1161 1088.5,-1182\"/>\n",
       "<text text-anchor=\"middle\" x=\"1026.5\" y=\"-1168.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126782872&#45;&gt;140341126782480 -->\n",
       "<g id=\"edge132\" class=\"edge\">\n",
       "<title>140341126782872&#45;&gt;140341126782480</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M994.3655,-1160.9123C966.3265,-1151.674 925.471,-1138.213 894.9716,-1128.164\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"896.0555,-1124.8361 885.4624,-1125.031 893.8649,-1131.4846 896.0555,-1124.8361\"/>\n",
       "</g>\n",
       "<!-- 140341126808632 -->\n",
       "<g id=\"node127\" class=\"node\">\n",
       "<title>140341126808632</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1115,-1245.5 1002,-1245.5 1002,-1224.5 1115,-1224.5 1115,-1245.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1058.5\" y=\"-1231.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AsStridedBackward</text>\n",
       "</g>\n",
       "<!-- 140341126808632&#45;&gt;140341126782872 -->\n",
       "<g id=\"edge133\" class=\"edge\">\n",
       "<title>140341126808632&#45;&gt;140341126782872</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1053.0716,-1224.2281C1048.5391,-1215.2338 1041.9578,-1202.1741 1036.4792,-1191.3025\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1039.4741,-1189.4679 1031.8482,-1182.1128 1033.2229,-1192.6181 1039.4741,-1189.4679\"/>\n",
       "</g>\n",
       "<!-- 140341126808464 -->\n",
       "<g id=\"node128\" class=\"node\">\n",
       "<title>140341126808464</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1077,-1309 1006,-1309 1006,-1288 1077,-1288 1077,-1309\"/>\n",
       "<text text-anchor=\"middle\" x=\"1041.5\" y=\"-1295.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CopySlices</text>\n",
       "</g>\n",
       "<!-- 140341126808464&#45;&gt;140341126808632 -->\n",
       "<g id=\"edge134\" class=\"edge\">\n",
       "<title>140341126808464&#45;&gt;140341126808632</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1044.3838,-1287.7281C1046.7426,-1278.9174 1050.1458,-1266.2055 1053.0196,-1255.4708\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1056.4535,-1256.1778 1055.6588,-1245.6128 1049.6917,-1254.3675 1056.4535,-1256.1778\"/>\n",
       "</g>\n",
       "<!-- 140341126808912 -->\n",
       "<g id=\"node129\" class=\"node\">\n",
       "<title>140341126808912</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1104,-1366 947,-1366 947,-1345 1104,-1345 1104,-1366\"/>\n",
       "<text text-anchor=\"middle\" x=\"1025.5\" y=\"-1352.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n",
       "</g>\n",
       "<!-- 140341126808912&#45;&gt;140341126808464 -->\n",
       "<g id=\"edge135\" class=\"edge\">\n",
       "<title>140341126808912&#45;&gt;140341126808464</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1028.5095,-1344.7787C1030.5431,-1337.5338 1033.2932,-1327.7367 1035.7394,-1319.0221\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1039.1711,-1319.747 1038.504,-1309.1732 1032.4316,-1317.8552 1039.1711,-1319.747\"/>\n",
       "</g>\n",
       "<!-- 140341126808968&#45;&gt;140341126808912 -->\n",
       "<g id=\"edge136\" class=\"edge\">\n",
       "<title>140341126808968&#45;&gt;140341126808912</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M883.006,-1401.9123C911.3692,-1392.674 952.697,-1379.213 983.549,-1369.164\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"984.7437,-1372.456 993.1681,-1366.031 982.5757,-1365.8001 984.7437,-1372.456\"/>\n",
       "</g>\n",
       "<!-- 140341126809024 -->\n",
       "<g id=\"node131\" class=\"node\">\n",
       "<title>140341126809024</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1087.5,-1423 963.5,-1423 963.5,-1402 1087.5,-1402 1087.5,-1423\"/>\n",
       "<text text-anchor=\"middle\" x=\"1025.5\" y=\"-1409.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126809024&#45;&gt;140341126808912 -->\n",
       "<g id=\"edge138\" class=\"edge\">\n",
       "<title>140341126809024&#45;&gt;140341126808912</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1025.5,-1401.7787C1025.5,-1394.6134 1025.5,-1384.9517 1025.5,-1376.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1029.0001,-1376.1732 1025.5,-1366.1732 1022.0001,-1376.1732 1029.0001,-1376.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126809136 -->\n",
       "<g id=\"node132\" class=\"node\">\n",
       "<title>140341126809136</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1156,-1493 895,-1493 895,-1459 1156,-1459 1156,-1493\"/>\n",
       "<text text-anchor=\"middle\" x=\"1025.5\" y=\"-1479.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._residual_stack._layers.1._block.1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1025.5\" y=\"-1466.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126809136&#45;&gt;140341126809024 -->\n",
       "<g id=\"edge139\" class=\"edge\">\n",
       "<title>140341126809136&#45;&gt;140341126809024</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1025.5,-1458.9832C1025.5,-1451.1157 1025.5,-1441.6973 1025.5,-1433.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1029.0001,-1433.3686 1025.5,-1423.3687 1022.0001,-1433.3687 1029.0001,-1433.3686\"/>\n",
       "</g>\n",
       "<!-- 140341126808072 -->\n",
       "<g id=\"node133\" class=\"node\">\n",
       "<title>140341126808072</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"915.5,-1182 791.5,-1182 791.5,-1161 915.5,-1161 915.5,-1182\"/>\n",
       "<text text-anchor=\"middle\" x=\"853.5\" y=\"-1168.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126808072&#45;&gt;140341126782480 -->\n",
       "<g id=\"edge140\" class=\"edge\">\n",
       "<title>140341126808072&#45;&gt;140341126782480</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M853.5,-1160.7787C853.5,-1153.6134 853.5,-1143.9517 853.5,-1135.3097\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"857.0001,-1135.1732 853.5,-1125.1732 850.0001,-1135.1732 857.0001,-1135.1732\"/>\n",
       "</g>\n",
       "<!-- 140341126808744 -->\n",
       "<g id=\"node134\" class=\"node\">\n",
       "<title>140341126808744</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"984,-1252 723,-1252 723,-1218 984,-1218 984,-1252\"/>\n",
       "<text text-anchor=\"middle\" x=\"853.5\" y=\"-1238.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._residual_stack._layers.1._block.3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"853.5\" y=\"-1225.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 32, 1)</text>\n",
       "</g>\n",
       "<!-- 140341126808744&#45;&gt;140341126808072 -->\n",
       "<g id=\"edge141\" class=\"edge\">\n",
       "<title>140341126808744&#45;&gt;140341126808072</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M853.5,-1217.9832C853.5,-1210.1157 853.5,-1200.6973 853.5,-1192.4019\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"857.0001,-1192.3686 853.5,-1182.3687 850.0001,-1192.3687 857.0001,-1192.3686\"/>\n",
       "</g>\n",
       "<!-- 140341126781864 -->\n",
       "<g id=\"node135\" class=\"node\">\n",
       "<title>140341126781864</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"945.5,-877.5 821.5,-877.5 821.5,-856.5 945.5,-856.5 945.5,-877.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.5\" y=\"-863.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126781864&#45;&gt;140341126781696 -->\n",
       "<g id=\"edge142\" class=\"edge\">\n",
       "<title>140341126781864&#45;&gt;140341126781696</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M883.5,-856.2281C883.5,-847.5091 883.5,-834.9699 883.5,-824.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"887.0001,-824.1128 883.5,-814.1128 880.0001,-824.1129 887.0001,-824.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126782088 -->\n",
       "<g id=\"node136\" class=\"node\">\n",
       "<title>140341126782088</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"969.5,-954 801.5,-954 801.5,-920 969.5,-920 969.5,-954\"/>\n",
       "<text text-anchor=\"middle\" x=\"885.5\" y=\"-940.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_trans_1.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"885.5\" y=\"-927.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126782088&#45;&gt;140341126781864 -->\n",
       "<g id=\"edge143\" class=\"edge\">\n",
       "<title>140341126782088&#45;&gt;140341126781864</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M885.0056,-919.6966C884.7304,-910.0634 884.3858,-898.003 884.0958,-887.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"887.5926,-887.6872 883.8083,-877.7913 880.5954,-887.8872 887.5926,-887.6872\"/>\n",
       "</g>\n",
       "<!-- 140341126781920 -->\n",
       "<g id=\"node137\" class=\"node\">\n",
       "<title>140341126781920</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1119,-884 964,-884 964,-850 1119,-850 1119,-884\"/>\n",
       "<text text-anchor=\"middle\" x=\"1041.5\" y=\"-870.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_trans_1.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"1041.5\" y=\"-857.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126781920&#45;&gt;140341126781696 -->\n",
       "<g id=\"edge144\" class=\"edge\">\n",
       "<title>140341126781920&#45;&gt;140341126781696</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M999.1589,-849.9832C974.2535,-839.9737 943.1022,-827.454 919.4053,-817.9303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"920.6548,-814.6604 910.0709,-814.1788 918.0444,-821.1555 920.6548,-814.6604\"/>\n",
       "</g>\n",
       "<!-- 140341126781304 -->\n",
       "<g id=\"node138\" class=\"node\">\n",
       "<title>140341126781304</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1092.5,-623.5 968.5,-623.5 968.5,-602.5 1092.5,-602.5 1092.5,-623.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1030.5\" y=\"-609.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126781304&#45;&gt;140341126781192 -->\n",
       "<g id=\"edge145\" class=\"edge\">\n",
       "<title>140341126781304&#45;&gt;140341126781192</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1030.5,-602.2281C1030.5,-593.5091 1030.5,-580.9699 1030.5,-570.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1034.0001,-570.1128 1030.5,-560.1128 1027.0001,-570.1129 1034.0001,-570.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126781528 -->\n",
       "<g id=\"node139\" class=\"node\">\n",
       "<title>140341126781528</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1116.5,-700 948.5,-700 948.5,-666 1116.5,-666 1116.5,-700\"/>\n",
       "<text text-anchor=\"middle\" x=\"1032.5\" y=\"-686.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_trans_2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1032.5\" y=\"-673.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 768, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126781528&#45;&gt;140341126781304 -->\n",
       "<g id=\"edge146\" class=\"edge\">\n",
       "<title>140341126781528&#45;&gt;140341126781304</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1032.0056,-665.6966C1031.7304,-656.0634 1031.3858,-644.003 1031.0958,-633.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1034.5926,-633.6872 1030.8083,-623.7913 1027.5954,-633.8872 1034.5926,-633.6872\"/>\n",
       "</g>\n",
       "<!-- 140341126781360 -->\n",
       "<g id=\"node140\" class=\"node\">\n",
       "<title>140341126781360</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1266,-630 1111,-630 1111,-596 1266,-596 1266,-630\"/>\n",
       "<text text-anchor=\"middle\" x=\"1188.5\" y=\"-616.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_trans_2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"1188.5\" y=\"-603.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768)</text>\n",
       "</g>\n",
       "<!-- 140341126781360&#45;&gt;140341126781192 -->\n",
       "<g id=\"edge147\" class=\"edge\">\n",
       "<title>140341126781360&#45;&gt;140341126781192</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1146.1589,-595.9832C1121.2535,-585.9737 1090.1022,-573.454 1066.4053,-563.9303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1067.6548,-560.6604 1057.0709,-560.1788 1065.0444,-567.1555 1067.6548,-560.6604\"/>\n",
       "</g>\n",
       "<!-- 140341126753024 -->\n",
       "<g id=\"node141\" class=\"node\">\n",
       "<title>140341126753024</title>\n",
       "<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"1239.5,-369.5 1115.5,-369.5 1115.5,-348.5 1239.5,-348.5 1239.5,-369.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"1177.5\" y=\"-355.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 140341126753024&#45;&gt;140341126752240 -->\n",
       "<g id=\"edge148\" class=\"edge\">\n",
       "<title>140341126753024&#45;&gt;140341126752240</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1177.5,-348.2281C1177.5,-339.5091 1177.5,-326.9699 1177.5,-316.3068\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.0001,-316.1128 1177.5,-306.1128 1174.0001,-316.1129 1181.0001,-316.1128\"/>\n",
       "</g>\n",
       "<!-- 140341126781024 -->\n",
       "<g id=\"node142\" class=\"node\">\n",
       "<title>140341126781024</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1263.5,-446 1095.5,-446 1095.5,-412 1263.5,-412 1263.5,-446\"/>\n",
       "<text text-anchor=\"middle\" x=\"1179.5\" y=\"-432.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_trans_3.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"1179.5\" y=\"-419.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (768, 1025, 3)</text>\n",
       "</g>\n",
       "<!-- 140341126781024&#45;&gt;140341126753024 -->\n",
       "<g id=\"edge149\" class=\"edge\">\n",
       "<title>140341126781024&#45;&gt;140341126753024</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1179.0056,-411.6966C1178.7304,-402.0634 1178.3858,-390.003 1178.0958,-379.8518\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1181.5926,-379.6872 1177.8083,-369.7913 1174.5954,-379.8872 1181.5926,-379.6872\"/>\n",
       "</g>\n",
       "<!-- 140341126752632 -->\n",
       "<g id=\"node143\" class=\"node\">\n",
       "<title>140341126752632</title>\n",
       "<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"1413,-376 1258,-376 1258,-342 1413,-342 1413,-376\"/>\n",
       "<text text-anchor=\"middle\" x=\"1335.5\" y=\"-362.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">_decoder._conv_trans_3.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"1335.5\" y=\"-349.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1025)</text>\n",
       "</g>\n",
       "<!-- 140341126752632&#45;&gt;140341126752240 -->\n",
       "<g id=\"edge150\" class=\"edge\">\n",
       "<title>140341126752632&#45;&gt;140341126752240</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M1293.1589,-341.9832C1268.2535,-331.9737 1237.1022,-319.454 1213.4053,-309.9303\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"1214.6548,-306.6604 1204.0709,-306.1788 1212.0444,-313.1555 1214.6548,-306.6604\"/>\n",
       "</g>\n",
       "<!-- 93924478888592 -->\n",
       "<g id=\"node144\" class=\"node\">\n",
       "<title>93924478888592</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"653.5,-5464.5 585.5,-5464.5 585.5,-5443.5 653.5,-5443.5 653.5,-5464.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"619.5\" y=\"-5450.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">NoneType</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fa3b701e1d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dot(model(train[0]),  params  = dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor(-7.7367, device='cuda:0')\n",
      "std: tensor(15.3623, device='cuda:0')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mean = 0.\n",
    "meansq = 0.\n",
    "for data in training_loader:\n",
    "    mean = data[0].mean()\n",
    "    meansq = (data[0]**2).mean()\n",
    "\n",
    "std = torch.sqrt(meansq - mean**2)\n",
    "print(\"mean: \" + str(mean))\n",
    "print(\"std: \" + str(std))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 iterations\n",
      "recon_error: 13.774\n",
      "perplexity: 4.017\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 iterations\n",
      "recon_error: 9.107\n",
      "perplexity: 2.838\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 iterations\n",
      "recon_error: 7.147\n",
      "perplexity: 3.105\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 iterations\n",
      "recon_error: 6.688\n",
      "perplexity: 3.580\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 iterations\n",
      "recon_error: 6.839\n",
      "perplexity: 4.053\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 iterations\n",
      "recon_error: 8.142\n",
      "perplexity: 4.165\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 iterations\n",
      "recon_error: 9.395\n",
      "perplexity: 4.224\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 iterations\n",
      "recon_error: 7.473\n",
      "perplexity: 5.527\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 iterations\n",
      "recon_error: 6.869\n",
      "perplexity: 7.272\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 iterations\n",
      "recon_error: 6.526\n",
      "perplexity: 7.007\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 iterations\n",
      "recon_error: 6.398\n",
      "perplexity: 6.938\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 iterations\n",
      "recon_error: 6.455\n",
      "perplexity: 6.560\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 iterations\n",
      "recon_error: 7.099\n",
      "perplexity: 6.827\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1400 iterations\n",
      "recon_error: 6.553\n",
      "perplexity: 6.151\n",
      "\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n",
      "Data size\n",
      "torch.Size([10, 1025, 616])\n",
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n",
      "shape of x in Decoder.forward._conv_trans_3 torch.Size([10, 1025, 1232])\n",
      "input_features_size 616\n",
      "output_features_size 1232\n",
      "x_recon size torch.Size([10, 1025, 616])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 iterations\n",
      "recon_error: 6.640\n",
      "perplexity: 5.152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "train_res_recon_error = []\n",
    "train_res_perplexity = []\n",
    "\n",
    "for i in xrange(num_training_updates):\n",
    "    (data, _) = next(iter(training_loader))\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    print(\"Data size\")\n",
    "    print(data.size())\n",
    "\n",
    "    vq_loss, data_recon, perplexity = model(data)\n",
    "    recon_error = F.mse_loss(data_recon, data) / std\n",
    "    loss = recon_error + vq_loss\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_res_recon_error.append(recon_error.item())\n",
    "    train_res_perplexity.append(perplexity.item())\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        print('%d iterations' % (i+1))\n",
    "        print('recon_error: %.3f' % np.mean(train_res_recon_error[-100:]))\n",
    "        print('perplexity: %.3f' % np.mean(train_res_perplexity[-100:]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_res_recon_error_smooth = savgol_filter(train_res_recon_error, 201, 7)\n",
    "train_res_perplexity_smooth = savgol_filter(train_res_perplexity, 201, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'iteration')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = plt.figure(figsize=(16,8))\n",
    "ax = f.add_subplot(1,2,1)\n",
    "ax.plot(train_res_recon_error_smooth)\n",
    "ax.set_yscale('log')\n",
    "ax.set_title('Smoothed NMSE.')\n",
    "ax.set_xlabel('iteration')\n",
    "\n",
    "ax = f.add_subplot(1,2,2)\n",
    "ax.plot(train_res_perplexity_smooth)\n",
    "ax.set_title('Smoothed Average codebook usage (perplexity).')\n",
    "ax.set_xlabel('iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reconstructions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (_encoder): Encoder(\n",
       "    (_conv_1): Conv1d(1025, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_2): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_3): Conv1d(768, 768, kernel_size=(4,), stride=(1,), padding=(2,))\n",
       "    (_conv_4): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_5): Conv1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_residual_stack): ResidualStack(\n",
       "      (_layers): ModuleList(\n",
       "        (0): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (_pre_vq_conv): Conv1d(768, 64, kernel_size=(1,), stride=(1,))\n",
       "  (_vq_vae): VectorQuantizer(\n",
       "    (_embedding): Embedding(29, 64)\n",
       "  )\n",
       "  (_decoder): Decoder(\n",
       "    (_conv_1): Conv1d(64, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_upsample): Upsample(scale_factor=2.0, mode=nearest)\n",
       "    (_residual_stack): ResidualStack(\n",
       "      (_layers): ModuleList(\n",
       "        (0): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Residual(\n",
       "          (_block): Sequential(\n",
       "            (0): ReLU(inplace=True)\n",
       "            (1): Conv1d(768, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "            (2): ReLU(inplace=True)\n",
       "            (3): Conv1d(32, 768, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (_conv_trans_1): ConvTranspose1d(768, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (_conv_trans_2): ConvTranspose1d(768, 768, kernel_size=(3,), stride=(1,))\n",
       "    (_conv_trans_3): ConvTranspose1d(768, 1025, kernel_size=(3,), stride=(1,), padding=(3,))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "#(valid_originals, _) = next(iter(validation_loader))\n",
    "#valid_originals = valid_originals.to(device)\n",
    "\n",
    "#vq_output_eval = model._pre_vq_conv(model._encoder(valid_originals))\n",
    "#_, valid_quantize, _, _ = model._vq_vae(vq_output_eval)\n",
    "#valid_reconstructions = model._decoder(valid_quantize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model::forward\n",
      "shape of inputs in Encoder.forward torch.Size([10, 1025, 616])\n",
      "shape of x in Encoder.forward._conv_1 torch.Size([10, 768, 616])\n",
      "shape of x in Encoder.forward.relu_2 torch.Size([10, 768, 616])\n",
      "shape of x_conv_3 in Encoder.forward._conv_3 torch.Size([10, 768, 617])\n",
      "shape of x_conv_4 in Encoder.forward._conv_4 torch.Size([10, 768, 617])\n",
      "shape of x_conv_5 in Encoder.forward._conv_5 torch.Size([10, 768, 617])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 617])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 617])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 617]) \n",
      "shape of _residual_stack in Encoder.forward torch.Size([10, 768, 617])\n",
      "shape of inputs in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of flat_input in VectorQuantizer.forward torch.Size([6170, 64])\n",
      "device of flat_input cuda:0\n",
      "shape of quantized in VectorQuantizer.forward torch.Size([64, 617, 10])\n",
      "shape of inputs in Decoder.forward torch.Size([10, 64, 617])\n",
      "shape of x in Decoder.forward._conv_1 torch.Size([10, 768, 617])\n",
      "shape of x in Decoder.forward._upsample torch.Size([10, 768, 1234])\n",
      "shape of x in ResidualStack.forward torch.Size([10, 768, 1234])\n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 0 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Residual.forward torch.Size([10, 768, 1234])\n",
      "Iteration 1 shape of x in ResidualStack.forward torch.Size([10, 768, 1234]) \n",
      "shape of x in Decoder.forward._residual_stack torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_1 torch.Size([10, 768, 1234])\n",
      "shape of x in Decoder.forward._conv_trans_2 torch.Size([10, 768, 1236])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 11.17 GiB total capacity; 10.62 GiB already allocated; 24.75 MiB free; 240.11 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-d5ebbd22fa42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mvq_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_recon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-3c0c6d858839>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m#print(\"quantized \")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m#print( quantized.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0minput_features_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-cb265bf9118e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape of x in Decoder.forward._conv_trans_2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_trans_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shape of x in Decoder.forward._conv_trans_3'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    629\u001b[0m         return F.conv_transpose1d(\n\u001b[1;32m    630\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             output_padding, self.groups, self.dilation)\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 11.17 GiB total capacity; 10.62 GiB already allocated; 24.75 MiB free; 240.11 MiB cached)"
     ]
    }
   ],
   "source": [
    "(data, _) = next(iter(training_loader))\n",
    "data = data.to(device)\n",
    "\n",
    "vq_loss, data_recon, perplexity = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -2.0134,  -4.1851,  -5.3504,  ...,  -0.2854,  -0.2738,  -0.2639],\n",
       "        [  3.7790,   4.5523,   4.6093,  ...,   0.2346,   0.2262,   0.2191],\n",
       "        [  2.6847,   4.0253,   4.5944,  ...,   0.2590,   0.2485,   0.2392],\n",
       "        ...,\n",
       "        [-43.2679, -41.3331, -42.4862,  ...,  -2.0128,  -1.9371,  -1.8740],\n",
       "        [-43.7020, -41.1623, -42.1783,  ...,  -2.0123,  -1.9371,  -1.8743],\n",
       "        [-43.4860, -41.2254, -42.4294,  ...,  -2.0090,  -1.9331,  -1.8703]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_recon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '/home/ubuntu/voice_conversion/data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = (data[0].to(torch.device(\"cpu\"))).detach().numpy();\n",
    "data_griffin_lim = librosa.griffinlim(data_np)\n",
    "np.save(os.path.join('/home/ubuntu/voice_conversion/data/output', 'data.wav'), data_griffin_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert torch tensor to numpy array\n",
    "data_recon_np = (data_recon[0].to(torch.device(\"cpu\"))).detach().numpy();\n",
    "data_recon_griffin_lim = librosa.griffinlim(data_recon_np)\n",
    "np.save(os.path.join('/home/ubuntu/voice_conversion/data/output', 'data_recon.wav'), data_recon_griffin_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecVNX9//HXhwWk96qgIAh+7ShW1Ghs2DAm0SiWaFQ0iYqdaBLRWL7G2GNJFDR+jcafXWPvKCoiCAgKKiDI0lEB6bD7+f1xZnZmd2fbzOzcmeX9fDzmMbece87nzuzOZ+69Z+4xd0dERCTfNIo6ABERkVSUoEREJC8pQYmISF5SghIRkbykBCUiInlJCUpERPKSEpRIlpnZVWY2Kttla1GXm1nfbNQlkg9Mv4MSqZ6ZnQFcCvQBVgLPAle6+/Io46rIzBzYzt1nRh2LSDboCEqkGmZ2KfBX4HKgLbAPsA3whpk1TVG+cW4jFGm4lKBEqmBmbYBrgQvc/VV33+juc4ATCUnqVDO7xsyeMrN/m9lK4IzYsn8n1XO6mc01s+/M7M9mNsfMDo2tKytrZr1ip+l+bWbfmtkyM/tjUj17mdlHZrbczBaa2d2pkqRIQ6EEJVK1/YBmwDPJC919FfAKcFhs0XHAU0A74NHksma2A3AvcArQnXAUtlUN7e4P9AcOAa42s/+JLS8BLgY6AfvG1v8ujf0SKQhKUCJV6wQsc/dNKdYtjK0H+Mjdn3P3UndfW6HcL4H/uvtYd98AXA3UdOH3Wndf6+5TgCnArgDuPtHdx7n7ptiR3D+Bn6S3ayL5T+fLRaq2DOhkZo1TJKnusfUA86qpY8vk9e6+xsy+q6HdRUnTa4BWAGbWD7gNGAi0IPz/TqxpJ0QKlY6gRKr2EbAe+HnyQjNrCRwJvBVbVN0R0UKgR9K2zYGOacZzHzCD0FOvDXAVYGnWJZL3lKBEquDuKwidJP5uZoPNrImZ9QKeBIqBR2pRzVPAsWa2X6xDw7Wkn1RaE7q5rzKz7YHfplmPSEFQghKphrvfTDhSuYWQHD4mnLI7xN3X12L7z4ELgMcJR1M/AksIR2Z1dRkwNFbHA8D/S6MOkYKhH+qK5JCZtQKWE07TfRN1PCL5TEdQIvXMzI41sxaxa1e3AFOBOdFGJZL/lKBE6t9xwILYYzvgJNepC5Ea6RSfiIjkJR1BiYhIXorkh7qdOnXyXr16RdG0iIhEbOLEicvcvXNN5SJJUL169WLChAlRNC0iIhEzs7m1KadTfCIikpeUoEREJC8pQUnGlqxews0f3Bx1GCLSwChBScYen/Y4I94cEXUYItLAKEHV4E9v/4l/Tvhn1GGIiGx2lKBqcMP7N3D9+9dHHUZe04+9RaQ+5EWCevubt3l/7vtRhyEiInkkL0bUPeT/DqFZ42as/WPF0bJFRGRzlRdHUACWxwOD5nNs+cCrHVBWRCQ9kSUou9YYP398Yt6UBArV2o068hWR7Iv0COqbHxLjtWXjKGXJ6iUZ1yF1d9XbV0Udgog0QFlJUGY2x8ymmtlkM6v1TfaSTw1l4wiq6y1dmb50esb1bC6+X/s9t310W43l5iyfo+QvIjmXzSOog919N3cfmM7G8SOoXe7bhUWrFlVZbr/R+zHynZFsKNmQcv2qDavSaX6z9Oz0Z7n09UurLdP0uqb0vrM3hz9yeKV1xSuLKSktqa/wRGQzlz+dJGJHUFOXTOXzJZ8D8O6cdysloo+KP+Iv7/2FM547o9zyOcvnALB201rWbVrH4lWLsxpbqZcy6MFBWaszKj+u/7HSso/mfYRdm/oIdmPpRgBWrF9RaV3P23sy6tNR2Q1QRCQmWwnKgdfNbKKZDUtVwMyGmdkEM5uwdOnSyuuTrkGt27QOu9Y4+OGDeXza4wA8PPlhfvfS78rKfPndl+W2/27NdwCc//L5XPjKhXS7tVvGO5WspLSED+d9mNU6c21DyQba3NSGl79+udzysd+OBcIti6YsmgLAGc+dwbwV88rKzFk+h3Wb1vH4tMdpel1TxswZA6ROXCIi2ZCt30ENcvcFZtYFeMPMZrj7e8kF3P1+4H6AXQbs4gClXsrHxR+H9UnXo9ZuSvQKix9B3TX+Lj5d+GmNgUxdMpWt225dafl5L55H06Km3HXkXTXW8c0P3/Dbl37Lnw78U9myccXj4vtRsD0Ot71zW4CyxBN/za948woATn765LB8pPPwlIfp075Pue073tyRNRvXAOHH1QBFVlT/gYvIZikrR1DuviD2vAR4FtiruvJTF08F4NWZr7LP6H2AcAR1+0e3x+srK1tSWsId4+6oMjlNXjSZdZvWlVtW6qWVyv1z4j/5+/i/s37Tep6Z/kzZEUAqr858lddmvcYBDx1QFs+8leU/1AvR/B/nA3DeS+fVqvym0k3l5uPJCeCeT+4BUr/WIiLZkHGCMrOWZtY6Pg0cDkyrzbazf5hdNr1i/Qouef0SgHKdJM576Txu/ejWStt+uvBTjvj3EQz45wCa39C83LqZ388MsaW4rjJtyTR+8cQvOPXZU6vbp3Lz81bO47kZzwFw9/i7a9qtvPTD2h/Kza/duJZXZr5S7TZj542tct13a8Mp1fjRl4hItmXjCKorMNbMpgDjgZfc/dXabPjBvA9SLr/w1QvLzRevLE5Z7vVZr9fYRvK3/mTV/e4q1bonv3gSCEdXhahiZ5MWN7bgmenPpCwbT+zx03giIlHIOEG5+2x33zX22NHdb8hGYJmY9cOssumR74wst27l+pVAOCq6c9ydda67pqOOfFWocYvI5itvupln6twXzy2bTr4u8shnj/DunHfL5n/6fz8tm774tYsr1bPwx4U5+VGqu5f1PMyFM58/M2dtiYhkQ4NJUBMXTqxyXXKCSuY46zatY/8H9+fpL54GoM9dfbj63avrI8QyXyz9gocmP0Snv3Wq1BGhkKnDhIhkU14Mt1GfFq9ezLVjrq1yfbyDxQfzPmD5iOXlurjXhw0lG9jx3h3L5j9b/Bl7PrAnn533GU9+8STzV87ngSEPVNpu/ab1NLuhGT6y7r0Ic3V3jeKVxSm7+IuIpKPBJ6i6WPDjgnqpd9GqRXRr1Y1357zLwQ8fXG7d7B9mU+ql7HTfTmXLKiao+Svns0XjLdJu/4ulX6S9bV0s+HGBEpSIZE2DOcWXDd8s/6bmQlD24+LaWLVhFd1v7c6yNcuYsWxGnWMa9OAgetzeg40lG+u8bVwm29ZF+2btc9KOiGwelKCSHP3Y0bUqt8/ofeh2SzeWrVlWZZnv1nyHXWusWBduBbSxZCOrN6yuVO6EJ0+otGzKoikM/vdgjv3PsWW3V9ryti0BmLhgIhe9elGt4ozb/6H961Q+XYX8I2YRyT9KUGlavHoxnf/Wucr1P3/i50Ditk3L1y3nsjcuq1Xd3674ltdmvZbyN1fXv389d35c++7xS1dXvu9hfVEnCRHJJl2DyrKbxt5E/479eW9uuBXhMY8dA8AO9+5Q6zo+nh9OIabq4Re/o0Vt7wnY5ZYutW43Uxp6Q0SySQkqy65868py81XdBaM6N7xf82+dJy6cyMAtqx966yf/+kmd286EjqBEJJt0ii9DHW/uWO361RsrX3fKhvWb1qdc/uG8D8tu7xQ/isuV9SWpYxIRSUc0CaowR6tI6fu130fSbjwJJd9wF0Kvv/1G78c94+/JeUyXv3F5ztsUkYYrklN8hqnHV4YO/3diCHYf6bg7D056EIApi6dw/ivn5zymtlu0zXmbItJw6RpUFtz20W1csu8lfDL/k0ja73l7T0q9tN5+aFwbLZu05Of/8/PI2heRhkfXoLLg0tcvBUg5blUuFK8sjjQ5xakXn4hkk46gsiTV4Iibk1IvbVA3vhWR6OkISrKi1EvVi09EskoJSrKixEtYt2ld1GGISAOiBCVZUVJawn+/+m/UYYhIA6IEJVnhOGO/HRt1GCLSgGQlQZnZYDP70sxmmtkfslGnFCb15BORbMk4QZlZEXAPcCSwA3CymdX+zqjSoNT3iMQisvnIxhHUXsBMd5/t7huAx4HjslCvFKCet/eMOgQRaSCy8TuorYB5SfPFwN4VC5nZMGAYALojToO1fN3yzf43YSJSg+7sUZti2UhQqT6NKt1oz93vB+4HaLRVI9e9+BquswecXauxqkRk8/TA6gcW1qZcNhJUMZB8XqcHEP19dyQST57wJL/c4ZdRhyEieeyBlQ/UKkdk4xrUJ8B2ZtbbzJoCJwEvZKFeKUDH9Dsm6hBEpIHI+AjK3TeZ2fnAa0AR8KC7f55xZFKQmjVuFnUIItJAZOVmse7+MvByNuoSEREB3c08Zxr6II2NrBHD9x4edRgi0oDoVkc50pCTE0CRFbFV662iDkNEGhAlKMmKokZFuv4kIlmlBJUlX1/wddQhRKqRNaJpUdOowxCRBkQJKgsMo2+Hvtxz1D1RhxIZwyhqVBR1GCLSgChBZcE3w78B4LRdTouk/TFnjOHt09+OpO249SXrNWChiGSVElQWbNNuGwBab9E6Z23+ZrffcNfguwA4cJsDObj3way+anXO2q9oU+kmbv3o1sjaF5GGJ5IE5d6we7TlwpkDzuSCvS/ARyZeyxZNWgAwesholl6+NOcx/XrXX+e8TRFpuPQ7qAyNO2tc1CGUk5ywcu3YfsdG1raINDw6xZehvXtUGlmEIkt0FmjcqH6+A/Rq16vGMpPPnVwvbVdFnSREJJuUoLJs3sXzWHbFMrZuuzUAV+x3RZ3rePZXz1a5Lv5box5tetRYz67ddmVI/yF1bj9djUx/TiKSPfpEycC+PfattKxHmx60a9aO3w38HQC/3fO3ACy8dCHNGzevVb3xI7DkI7G4i/a+qE4xPn/S83Uqn4lU8YqIpEsJKg2tmrZi/Nnj+fCsD6ssc+l+l3LxPheXzbs7tx1xW6Vy5+1xXqVlB2xzAM/+6lme+dUzZcuuPvBqAEYeNJKZF8ysU7zH9T+uTuXTpSMoEckmfaIkmfH7GbUqN/vC2ey51Z7VlmncqDG3HXFb2f3p2jVrl7LcIdseUmlZu2bt+Nn2P2NI/yF8dNZHQOJIrFnjZvTp0KdWccaNGDSiTuXTtb5kfU7aEZHNgxJUktre0LVzy861rtPM8JFO8ybNOX774yutjx919O/Yny4tu1Rav0+PffCRzhZFW9S6zYpy9fss/VBXRLKpwSeoVk1bVbv+6O2OBmCXrrvQv2P/eo2la6uu+EinX8d+ZUdWg3oO4u3T32bG+TP44Dcf8Nl5n6Xctm2ztlzzk2vSanenLjulG3Kd7Nxl55y0IyKbhwafoFo2ackth91S5foXh77I2DPH8tbpb2FmnLrLqfV+09Mvz/+St3/9Ntt32p6urbpycO+DAejboS87d039Id/IGjHyoJH1GlemdDdzEcmmBpOgnvjlEymXb912a84ccGbZ/F5b7VU2HT+yGLT1IDq16ATAI8c/wp2D76zHSIN+Hfsx/ffT672dXDKzqEMQkQakwSSo5I4DyddyLt/vcjo071A2f9/R95VNV/V7I6PhfdAuvHRh1CGIiNRJRgnKzK4xs/lmNjn2OCpbgdVV8v39knvMnbDjCSnL9WzTk74d+ta5naO2i2wXM1KxC/gOnXeosmz8JrQiIlHKxhHU7e6+W+zxcl02rNirrX2z9gA8ecKTZcuuO/g6Ttn5lJTbP/er54BwlJSsddPQa+2mQ26qtE3rLVrTdou21Sanir35mjRqwj+O/gcAtx9xe5Xb5bP4axL3+e8+54FjH0hZ9oK9LwDgsn0vq7HeC/e6MPPgRERSiOQUX5tmbYDy3+LbNWvHu2e8C5Q/GurasmulBASwe/fdOW774/CRzs2H3VxuXbdW3QAYsX/l3//069iPby/+lheHvlhlfC2btCw33711d9o2awvAdh22q27X8lbzJom7WBzU6yCg5lOZ1fWAPGf3c4Da3XJJRCQd2UhQ55vZZ2b2oJm1r6qQmQ0zswlmNqFdSTgFt1OXncruvu3u7NJ1l0rbFTUqYtduuzKo56BaB5TqYv2kcycx5bwpALTZok3Z0BSpDN15KNN/P73cncEP2PqAKusuFPHejBUHVuzdrnfZ9Lbtty2b3rL1luXKxe9mkbyukF8PEclvNSYoM3vTzKaleBwH3Af0AXYDFgJVjljn7ve7+0B3H9i5c+UfuiafVmvfvD13HHEHEI54AJ4+8ela9Xq7cK8LOXmnk8t+3xS3W7fdUibAVIoaFbF9p+2TY6drq6612jafXbrfpRy13VFlR1Dx1zx+hLp8xPKy17j44mLO2v2ssm2bFjXl2oOvZcUfVvDGaW9w6b6XAlBSWpLDPRCRzUmNY0G4+6G1qcjMHgCqPm9Wcztl000aNWH4PsMZvs/wsmVdW3UtlyTiH5Bx/TuFH9meusup7LnVngzdeWi6oaTUuFFjpv12WlbrjMJLQ1+qtGzozkNp1rhZ2WlMgK3abFWuTPyIqc0WbTh02/AnsUvXXThwmwPrMVoR2ZxlNFiRmXV393j/5eOBOn2CJ18DiX+b//A3H6YcYynu1VNepVe7XmUJKa6mO0Zkw45ddqz3NnKpa8uQ8Ns2a1vut2LJXj3lVW4bd1vKu0TET5mKiNSHTEfTu9nMdgMcmAOcW5eNk0/rxY+g9u1ZeQiLZEf0PaLKddu03Ybe7XtXuV7KO6bfMSy7fFm1ZY7oe0S1r7mISH3JKEG5+2k1l8qdORfNiTqEgmJmdGzRMeN6BnQbwKRFk7IQkYhIQmR3krhy/ys5bNvDyuZreydxyT+n73p61CGISAOU6Sm+tN14yI3l5pM7SYiIiESWoJL179i/XA+yfKOjOxGR3MuLBPXpuZ82yBu0bi703olIfciLBFXdXR3yQS66sBcy3U1CROpDXiSofDbrwlk0b9y85oKbMR1BiUh9UIKqQfK96SS15PG3RESypcEMWCjROXHHE1ly2ZKowxCRBkYJSjJmZnRuWfkGwCIimVCCEhGRvGRR/EDWzH4Evsx5w/WjE1D9De0Kh/YlP2lf8pP2JX3buHuNp12i6iTxpbsPjKjtrDKzCdqX/KN9yU/al/yUr/uiU3wiIpKXlKBERCQvRZWg7o+o3fqgfclP2pf8pH3JT3m5L5F0khAREamJTvGJiEheUoISEZG8lNMEZWaDzexLM5tpZn/IZdvZZmYPmtkSM5sWdSyZMrOeZvaOmU03s8/NbHjUMaXLzJqZ2XgzmxLbl2ujjikTZlZkZpPM7MWoY8mUmc0xs6lmNtnMJkQdTybMrJ2ZPWVmM2L/N/tGHVM6zKx/7P2IP1aa2UVRxxWXs2tQZlYEfAUcBhQDnwAnu/sXOQkgy8zsQGAV8H/uvlPU8WTCzLoD3d39UzNrDUwEflaI742FsT9auvsqM2sCjAWGu/u4iENLi5ldAgwE2rj7MVHHkwkzmwMMdPeC/3GrmT0MvO/uo8ysKdDC3ZdHHVcmYp/R84G93X1u1PFAbo+g9gJmuvtsd98APA4cl8P2s8rd3wO+jzqObHD3he7+aWz6R2A6sFW0UaXHg1Wx2SaxR0H2BDKzHsDRwKioY5EEM2sDHAiMBnD3DYWenGIOAWblS3KC3CaorYB5SfPFFOiHYENmZr2AAcDH0UaSvthpscnAEuANdy/UfbkDuAIojTqQLHHgdTObaGbDog4mA9sCS4GHYqdfR5lZy6iDyoKTgP9EHUSyXCaoVKPaFeQ324bKzFoBTwMXufvKqONJl7uXuPtuQA9gLzMruFOwZnYMsMTdJ0YdSxYNcvfdgSOB38dOkxeixsDuwH3uPgBYDRT6NfWmwBDgyahjSZbLBFUM9Eya7wEsyGH7Uo3Y9ZqngUfd/Zmo48mG2GmXd4HBEYeSjkHAkNh1m8eBn5rZv6MNKTPuviD2vAR4lnDavxAVA8VJR+ZPERJWITsS+NTdF0cdSLJcJqhPgO3MrHcsW58EvJDD9qUKsY4Fo4Hp7n5b1PFkwsw6m1m72HRz4FBgRrRR1Z27X+nuPdy9F+F/5W13PzXisNJmZi1jHXCInQ47HCjIHrDuvgiYZ2b9Y4sOAQquQ1EFJ5Nnp/cgh3czd/dNZnY+8BpQBDzo7p/nqv1sM7P/AAcBncysGBjp7qOjjSptg4DTgKmxazcAV7n7yxHGlK7uwMOxHkmNgCfcveC7aDcAXYFnw3chGgOPufur0YaUkQuAR2NftmcDZ0YcT9rMrAWhd/W5UcdSkW51JCIieUl3khARkbykBCUiInlJCUpERPKSEpSIiOQlJSgREclLSlAiIpKXlKBERCQvKUGJiEheUoISEZG8pAQlIiJ5SQlKRETykhKUiIjkJSUoiYyZ/cPM/pw0/1szW2xmq8yso5kNMrOvY/M/M7NXzOzX9RBHvdQrQez92zbqOKTw6G7mkhVmdhJwMbATYYTRb4CHCaOO1vhHFhswcSWwj7tPiS17C3jB3e/MQnxnAGe7+/6Z1lXIzOxfhMH2/lRP9b8L/NvdR9VH/bJ50RGUZMzMLgXuBP4GdCOM/XMeYZypplVsU1RhUVegGZA8Rtg2FeYLigUF9T9mZjkbI06kRu6uhx5pP4C2hCOmX9RQ7l/AfcDLsfKHxpZdD/SLLXNgFfA2MAsoBdbGlm1BGL797Fh9ZwBjgVuAHwhHbEdW0/4ZwNgq1lWs9wPgdmA5YTC6/WLL5wFLgF9X0867wA2xOtYCfWOv0WhgITA/ts9FSducA0wHfiSMzLp7bPn/xOpbTkjUQyq8nvcAL8W2+xjoE1tnsfiXACuAzwhHtsOAjcCG2Gv631j5OcCIWLn1hAEFHehbob3rk+aPAyYTjnpnAYNj+10CrIvVf3esbFldsdfi/4ClwFzgT0CjdN5TPRr+o6C+3Ule2peQPJ6vRdmhhA+x1oQPIgDc/Stgx9hsO3f/qbv3Ab4FjnX3Vu6+PkV9ewNfAp2Am4HRseHrM7U34cO6I/AY8DiwJyHZnArcbWatqtn+NEIyaE34EH4Y2BTbfgBhuPOzAczsBOAa4HSgDTAE+C52yvO/wOtAFxIjuPZPaudk4FqgPTCT8NoSq/9AQuJvB/wK+M7d7wceBW6OvabHVqjraMLrv6m6F8fM9iIkmctj9R8IzHH3PwLvA+fH6j8/xeZ/JySpbYGfxPY7eTTa+npPpQApQUmmOgHLkj/UzOxDM1tuZmvN7MCkss+7+wfuXuru67LQ9lx3f8DdSwhJoDvhVGGmvnH3h2L1/j+gJ/AXd1/v7q8TjkD6VrP9v9z989hr0gE4ErjI3Ve7+xLC0c1JsbJnExLGJx7MdPe5wD5AK+Amd9/g7m8DLxISSdwz7j4+1s6jwG6x5RsJyXF7wnXm6e6+sIZ9vsvd57n72lq8PmcBD7r7G7H3cr67z6hpo9hp3V8BV7r7j+4+B7iVkNDj6us9lQKkBCWZ+g7olHztwt33c/d2sXXJf2Pzstz2oqQ218QmW5nZAbGeY6vMLJ1rWIuTptfG6q+4rLojqOT93AZoAiyMJe3lwD8JR0UQkt+sFHVsCcxz99KkZXOBrZLmFyVNr4nHFEtmdxNOAS42s/vNrE018VaMuSZVxVyTToRrknOTllW5T8nvaRptSQOgBCWZ+ohw3eK4WpTNSZdRd38/doqplbvvWPMW2Q8haXoe4fXp5O7tYo82SXHNA/qkqGMB0LNCJ4utCdewag7A/S5334Nw6rQf4XRcxdiqihlCwmuRNN8tabqqmKurH2AZ4ehum6Rltd4n2fwoQUlG3H054TrIvWb2SzNrZWaNzGw3oGXE4VVkZtYs+VHfDcZOrb0O3GpmbWKvTR8z+0msyCjgMjPbI9brr6+ZbUPo9LAauMLMmpjZQcCxhOth1TKzPc1s79h1rNWETgslsdWLCdd/ajIZGGpmRWY2mHC9KG40cKaZHRLbn63MbPua6o+dtnsCuMHMWsf28xLg37WIRzZDSlCSMXe/mfBBcwWh59hiwmmsEcCHEYZW0X6E03Nljxx1qz6dcGrrC0LvtKcI11Zw9ycJnRseI/TGew7o4O4bCB0mjiQcedwLnF6baz2EzhYPxNqaSzjVekts3Whgh9jpxueqqWM4ISEuB06JxUUs5vGEjg23E3oJjiFxVHQn8Esz+8HM7kpR7wWEpDmb0FHmMeDBWuyTbIb0Q10REclLOoISEZG8pAQlIiJ5SQlKRETykhKUiIjkpUhuDNmpUyfv1atXFE2LiEjEJk6cuMzdO9dULpIE1atXLyZMmBBF0yIiEjEzm1tzKZ3iExGRPKUEJSIieUkJSkRE8pISlIiI5CUlKBERyUtKUCIikpeUoEREJC8pQYmISF4qmAS1Zg2YRR2FiIjkSsEkqB9/jDoCERHJpbxOUGawdGmYjo+ruGIFvP12dDGJiEhuZCVBmdkcM5tqZpPNLKs32Xv++fAcT1B//Sscckg2WxARkXyUzSOog919N3cfmI3KvvsuPJ9zTniOJyiNUC8isnnI21N8Dz1Ufn7RomjiEBGRaGQrQTnwuplNNLNhqQqY2TAzm2BmE5bGLyzFrF8fjoxWr04s27gxMT15MuyxR6whHUGJiGwWsjUe1CB3X2BmXYA3zGyGu7+XXMDd7wfuBxg4cGC5NNOsWXK58FxSklg2YEBiOnm5iIg0XFlJUO6+IPa8xMyeBfYC3qt+q9TeegsOPbTq9aWl6dQqIiKFJuNTfGbW0sxax6eBw4Fp6dY3fHj16+OnAYcODUdW112XbksiIpLPzDO8qGNm2wLPxmYbA4+5+w3VbdO790D/4x8n8MIL8N//ZtQ8oOtSIiKFxMwm1qbHd8YJKh1mAx2y93MpJSgRkcJR2wSVt93MRURk89YgEtTnn0cdgYiIZFuDSFBjx8KmTbBsWfbrXr48+3XW1u9/D9PS7G7yww8N99TnO+/k5ucGU6fCypW1L79iRfhNX7ZceilceGH26hMpNA0iQbnD9ddD587ll3/zTWb1btwI7dtnVse6dbDbbulte++98J//hOnFi2suv2gRPPpomO7QAR55JL1289Xy5SFh//Sn0LgxzJiRXj3PPQf/+7+p6583LzG/yy4hSdRWu3Zw1lnpxZTKHXfA3/+evfpAx7trAAAT6UlEQVRECk2DSFAAxcXh+YcfEneh2HZbmDOn6m1mzqz+FkqpfnN1663VH5k8+GCIIW7ZMpgyJRzh1dbXX1de1q0bPPlkYkysDRsS7axfD3Pnwp13wqmnJrZZuLDmdg44INwxvuKRghmMHl399rNnV7++JosX1/wzgSFD4I03QvI44gjYeefEunfeKV/24oth8OAw/dxz5e9MAuEIB+DPf4arrgrTo0aFI6VnnoGf/Qy23hrWrk28x+vW1bwf55yTeH9nzqy5fG1p/DPZ3DWIBPXGG4kPyw4d4OqrE+tSfcDEP4C22y586C1bVv0d0ktLw2lEgMsugyeeSKzbeefyXeXPOitxFJNs8uTa7UtJCfTrFxJQ3G23heeJExPLevcO+wpw7bXQq1f1dQJMmlT+Q/v998N+dekCRx2VWB5/Lc8+u+o6J02CPn1q3J1qPfts+fcqlf/+F556CoYNg/Hjqy43YUI44njtNbjoIjj+eGjVKrF+6dJwhLNqVfnTpuecE16/X/wCxowJy1q0gKefTpSZN6/8l5Jly2DECPj00zA/alTiaM49/L08/njlBLNpU0ic48aF+dWrE+/ziBGJL1kiEuPuOX/AHh7+lbPzaNmy8rJXXgnP06e7r1zp7u7+5z8n1t9+e3ju3dv97rvDdNybb7pvs4372rVh+Zgx4Xnq1MT2++zjXlwcps8/3/3KK90//jix/p//dL/iCvdvvw3z48e733ije//+7t9/H9r54Qf3v/3N/eqr3d99Nyxbtar8fnTv7r777mH6yivD85QpifX33+9+9tlh+tRTE/sB7jfdlJiOP0aMcF+/3v2RR9xPOy2xvGlT94kTK5dP5dhj3a+/PqyfNct9yZLy2z3zTKLsqlWp60guHzd1qvvSpZXLHHOM++DBld/je+91nznT/YEHqv7b6NIl1DN3bpg/44zEuhNPDM8nnFB5u/jfx7HHhuerr64c97nnVn69wH377RPTO+3k/tRTIdb4ss6dE9v17h3+RsH90EPD829+U/N7IFLIgAlem1xRm0LZfmQ7QVX3+M9/Egki1fo2bcrP77qr+1lnhenVq+vWVrNmiek+fcLzW2+F53Hjypf9+uvK248bV/7DLflDrrp299238gdafHq//SqXf/TR2u9T3FNPhflJkyrHtO++5duEkPAuuCBMd+3qfvPN7v36uZeUhA/ksWMTZRcscD/99MptPv98mD/88NSx3Xij+znn1LwP06ZVvz6eGJIfqb70JP65wuP4491LS9P7u4wnvrq8ByINRW0TVIP4oa6U98QTcOKJ2alrxQpo2zYx37Jl5Ws7dTF+POy1V83lRowIg1NCOA372mvpt5kt7jBrFvTtm/u216+Hpk1z365Ifdis7iQh0tCtWAFt2kQdhUh26E4SIg3ImjVRRyCSe0pQIgVgp52ijkAk9yJJUPp9h0jdfPdd1BGI5J6OoEREJC8pQYkUiFS3ZxJpyCLpxdeo0UB3Vy8+kbqK4N9VJOvUi08KViP9VVbp1VerXvf994n7DYo0BPookLyT6ia9Elx/fdXrttwy3KNRpKFQghIpIB98AO+9l3rd+vXl76SfzzZsqNsd/utizBh48cX6qVtyq3E2KjGzwcCdQBEwyt1vyka9IlLZT34Cd98d7ib/3HPh7u1LlybWb9oUhpxZtSoMo/L11+HIqnPnxB3w69vSpdC6NTRrFuY3bgx3yX/5ZSgqguHDoXlzeOABOOmksGzatHDH+R49wjZz5iTu0r96daijWbNwKrNx43AXfoD588M2Y8aE12LSpPKxnHJKGK6lqAhuvDGMZjBvXhiJ+/TTwxArkp8y7iRhZkXAV8BhQDHwCXCyu39R1TbqJCGSf5o2DeOdffNNSB7FxTBgQBheZMCAkCC22y4MkzJkCLz5JvzlL2FIlMMOg5//HKZPDwn0H/+Iem/qz0EHwbvvhunLLoNzzw1fFtasCfeqjA/n06JFYpsNG8L1wXbtwtAwffuGLwzuYd0WW9Su7Vmz0hvmZt268Fu6zp1DoobEM4Q4Kv4+taQklHEPp90bNQpl1qwJ8TZqFL4MNW4cxkHr2zccxTdrFl6Dpk3Dc4sW4W8nfm25SZMc3ovPzPYFrnH3I2LzV4Yd9io7xSpBiYhszgbiPqHGWzZk4xrUVkDSQNkUx5aVY2bDzGyCmU1wX1pxtYiISDnZSFCpsmClwzJ3v9/dB7r7QLPOWWhWREQK07q1tSmVjQRVDPRMmu8BLMhCvSJSzw4+ODyfeCI89ljogPD997BwYeh8MH9+uCa1enW4JlVSAosWhesmP/wAzzwTrm28+CLMnQuffBI6JMTV9tpKPrnssvD85pvhuX17OPlkuOIKOOssWLIE9t4brr4avvqq7sNVLloUrt2kM9RlutvV92PDhrqVh8+r7KOQLBvXoBoTOkkcAswndJIY6u6fV7WNrkGJZGbBgnDBev582GWX0FuvU6ewLvlfurQ0JJZ86KnmHnrybbFF6J137rnwpz9B9+5hfWlpKJN88b421q+H664LHTZmzYJ+/cLyf/0rXKQ/8sjQNb9x49BjsKQkXOifNw923DGbeyi1ldMBC83sKOAOQjfzB939hurKK0GJpG/JktAbq6J4L6zN/XZI8+aFb/Tp9HaT3KhtgsrK76Dc/WXg5WzUJSJVO+yw1MkJYN99QzfmzV3PnjWXkcKQlQQlkk2NGul2R1W5446q133wQe7iEMkFJSjJO0pOVdthh6rXaSBQaWh0Lz6RAjFmTNQRiOSWEpRIgTjwwKgjEMktJSgREclLkSSozb0brEhd/fznUUcgkns6ghIpAA89FHUEIrmnBCVSS/37R9e2zjrI5mizSVB1vX0KwFFHpd9emzbpb5upb77JXl3ucMYZifkTT8ysvvnza1fu9dcT00cckbpM+/awzTY11/XTn9auzZrMmBFuKZRru+0GrVrlvl2RqDX4BBUfXXP27PLLBw0Kz/HRO+PuuAMuuSRMP/VUeB46tPo2tt02PO+xR2JZ/Nf+n8fuSDhuXPkkuXYtHH54+Xrmz4dzzqlc/4AB1bd/yinl5+OjkO69N/zhD5XLv/BC1XUde2zlZQ89FAYkGzIE/v73sGznncNzq1ZwwgmVv+HfdRc8/XSYvuMO+OyzMBhe9+7hJqMrViTKrlsXRlqNcw93TJg5s+o4Aa65Bn72s+rLADzxRBhIriqp6khOyslat05MDxuW/pFNXYYknzQpvS9YIgXP3XP+gD2yei/d3r3Lz/fs6T5rVpieMcPLvPCC++WXu/fp4/7UU2H9ttu6v/xymI774gv38893X7s2LJ84MTyvWZNo469/DWUhlH3rLfeFC8N8t27uH37o/txz7t9+G5aNH+/+4ovuN92UaGfTJvdx49zHjHEvLg7LVq8O5YcMCc/HHOM+YECYvuqq8Lx8eSKOSZPczz47TA8fntiPijEecEB4vu0299JS9+nT3a++OlFP167uixeH8h07Jpan8o9/uD/8cFi/apX7+vVh+bHHhmVffpl6u4oqtlFa6l5SUrnM8ce7Dx5c+X2/5x73lSvDa9C1a+q/jYsvDvXMnRvmr702se7558PzL39Zebvbbw/Pp54anp9+unLc556bmG/SJLF82LDyfyezZoW/oYMPDsv69ElsN2xY4v284IKwn/fe637JJdW/ByKFDJjgtckVtSmU7Ue2E9Qll7gPHRqmO3cOH1we27vp06t+kdq0cT/6aPd169xHjaq8Pp6g3N2XLEnUOW1aoswVV4QPyMQLX76uefPCsilTqo4jWUlJKL9xYyIpvfRSmB4xIhHPWWe5t2gRpu+8Myz/wx/KJ6jkZOju/v33ISnGjRoVyvXv737KKYnlP/5Y84fjV19l/uEZb7868Q/xCy9MnaDilixJLH/hhcR+xcWTwKZN7h06lH+d4n878UdRkft774Xp5Ncl2VtvuS9dmqhj0aLwvNdeYdkXX7j/4heVt5szJ3yRSVXfmjXllxUVKUFJw7RZJah77w0f2BX/mcF9wYKqX6QffwxJqCrJCSruk0+qLu/uPnlySC5xxcV1/5CJbx9PUPHpDz90P+SQyuVLS8M2111XfYKq6Pvv3e+4IyTF0tLy6844w/3jj6vfvuLRTl2tX+/+/vvVl7nnnnBEtnFjOGKp+L4nGz3a/ZprwvT06eWTcbKddkq8TpMnu3/3XUgov/mNe9u2iXLVJahkr70WXr/kBJUNjRopQUnDVNsElZXhNurKbKBD9obbuO++MNbL738fxoaJKy0NNx5N16ZN0KRJ+DhMV0kJ3H03DB9e923N4Kqr4IZqBy9JWLcujIez445h29deq3ydq5Bt3BgGzmvfPlwXvOsu6Nix7vV89VUYsmL//csvLykJj6ZNw7wZ/PGPcP31tat3553h+OPDuETZUFSUGCNJpCHJ6XhQdVUfCeq887JWXd54+eUwhEL79lFHkl8WLIAtt6z/dpYvD51AGkd0S+VHHw0J8/TTo2lfpL5sVglq8WLo0iVr1YmISD2qbYJqEN3MlZxERBqeBpGgRESk4YkkQe2wA0yeDH/7WxSti4hIIcgoQZnZNWY238wmxx61ujlQ8+aw665w2WWVeyidcEL12150UXh+6SX4xz/glVfSiVxERPJdNvon3e7ut2ShHiB00W3eHB57LHTzrig+rHUm98kTEZH8lxfXoHr3Tkxvvz08/DCMHJm6bFRdfkVEJLeykaDON7PPzOxBM6vyFztmNszMJpjZhKVLl5ZbN3t24v4AccmJaPHipIDzIqWKiEh9q/Hj3szeNLNpKR7HAfcBfYDdgIXArVXV4+73u/tAdx/YOX6r72okD1fRpQt8+23NOyMiIg1HjSfM3P3Q2lRkZg8AdRhEoHrnnBNuXRQXP6KKX4MSEZGGLdNefN2TZo8HpmUWTkKTJuH5zTfLL+/QIVstiIhIPsv0is7NZjbVzD4DDgYuzkJMZQ48MAy6l+yii2DOnGy2IiIi+SijPnHuflq2AkllzJjEdPzUXpMmtRvmW0REClvB9Inr0AEOOijqKEREJFcKJkE1bQrvvBN1FCIikisFk6BERGTzogQlIiJ5SQlKRETykhKUiIjkJSUoERHJS0pQIiKSl5SgREQkLylBiYhIXjKvOOZ6Lho1+xH4MucN149OwLKog8gS7Ut+0r7kJ+1L+rZx9xrHXYpqfNov3X1gRG1nlZlN0L7kH+1LftK+5Kd83Red4hMRkbykBCUiInkpqgR1f0Tt1gftS37SvuQn7Ut+yst9iaSThIiISE10ik9ERPKSEpSIiOSlnCYoMxtsZl+a2Uwz+0Mu2842M3vQzJaY2bSoY8mUmfU0s3fMbLqZfW5mw6OOKV1m1szMxpvZlNi+XBt1TJkwsyIzm2RmL0YdS6bMbI6ZTTWzyWY2Iep4MmFm7czsKTObEfu/2TfqmNJhZv1j70f8sdLMLoo6rricXYMysyLgK+AwoBj4BDjZ3b/ISQBZZmYHAquA/3P3naKOJxNm1h3o7u6fmllrYCLws0J8b8zMgJbuvsrMmgBjgeHuPi7i0NJiZpcAA4E27n5M1PFkwszmAAPdveB/3GpmDwPvu/soM2sKtHD35VHHlYnYZ/R8YG93nxt1PJDbI6i9gJnuPtvdNwCPA8flsP2scvf3gO+jjiMb3H2hu38am/4RmA5sFW1U6fFgVWy2SexRkD2BzKwHcDQwKupYJMHM2gAHAqMB3H1DoSenmEOAWfmSnCC3CWorYF7SfDEF+iHYkJlZL2AA8HG0kaQvdlpsMrAEeMPdC3Vf7gCuAEqjDiRLHHjdzCaa2bCog8nAtsBS4KHY6ddRZtYy6qCy4CTgP1EHkSyXCcpSLCvIb7YNlZm1Ap4GLnL3lVHHky53L3H33YAewF5mVnCnYM3sGGCJu0+MOpYsGuTuuwNHAr+PnSYvRI2B3YH73H0AsBoo9GvqTYEhwJNRx5IslwmqGOiZNN8DWJDD9qUases1TwOPuvszUceTDbHTLu8CgyMOJR2DgCGx6zaPAz81s39HG1Jm3H1B7HkJ8CzhtH8hKgaKk47MnyIkrEJ2JPCpuy+OOpBkuUxQnwDbmVnvWLY+CXghh+1LFWIdC0YD0939tqjjyYSZdTazdrHp5sChwIxoo6o7d7/S3Xu4ey/C/8rb7n5qxGGlzcxaxjrgEDsddjhQkD1g3X0RMM/M+scWHQIUXIeiCk4mz07vQQ7vZu7um8zsfOA1oAh40N0/z1X72WZm/wEOAjqZWTEw0t1HRxtV2gYBpwFTY9duAK5y95cjjCld3YGHYz2SGgFPuHvBd9FuALoCz4bvQjQGHnP3V6MNKSMXAI/GvmzPBs6MOJ60mVkLQu/qc6OOpSLd6khERPKS7iQhIiJ5SQlKRETykhKUiIjkJSUoERHJS0pQIiKSl3LWzVykoTKzjsBbsdluQAnhVjgAa9x9v0gCEylw6mYukkVmdg2wyt1viToWkUKnU3wi9cjMVsWeDzKzMWb2hJl9ZWY3mdkpsbGrpppZn1i5zmb2tJl9EnsMinYPRKKjBCWSO7sCw4GdCXfu6OfuexGG07ggVuZO4HZ33xP4BRpqQzZjugYlkjufuPtCADObBbweWz4VODg2fSiwQ+yWQABtzKx1bJwukc2KEpRI7qxPmi5Nmi8l8b/YCNjX3dfmMjCRfKRTfCL55XXg/PiMme0WYSwikVKCEskvFwIDzewzM/sCOC/qgESiom7mIiKSl3QEJSIieUkJSkRE8pISlIiI5CUlKBERyUtKUCIikpeUoEREJC8pQYmISF76/xW36afY0+9HAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "ax = plt.subplot(2,1,1)\n",
    "librosa.display.waveplot(data_griffin_lim, color = 'g')\n",
    "plt.title('Original')\n",
    "plt.xlabel('')\n",
    "plt.subplot(2,1,2, sharex=ax, sharey=ax)\n",
    "plt.title('Griffin-Lim reconstruction')\n",
    "librosa.display.waveplot(data_recon_griffin_lim, color = 'b')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.wav.npy  data_recon.wav.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '/home/ubuntu/voice_conversion/data/output/data_recon.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b8c2f8bac3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mipd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/ubuntu/voice_conversion/data/output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_recon.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, filename, url, embed, rate, autoplay)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/lib/display.py\u001b[0m in \u001b[0;36m_make_wav\u001b[0;34m(self, data, rate)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0mnchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/home/ubuntu/voice_conversion/data/output/data_recon.wav'"
     ]
    }
   ],
   "source": [
    "ipd.Audio(os.path.join('/home/ubuntu/voice_conversion/data/output', 'data_recon.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.7581688 ,  1.6917429 ,  0.856833  , ..., -0.01163115,\n",
       "       -0.03142432,  0.0299731 ], dtype=float32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_recon_griffin_lim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'umap' has no attribute 'UMAP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-e1a132bdb910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m proj = umap.UMAP(n_neighbors=3,\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0mmin_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  metric='cosine').fit_transform(model._vq_vae._embedding.weight.data.cpu())\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'umap' has no attribute 'UMAP'"
     ]
    }
   ],
   "source": [
    "proj = umap.UMAP(n_neighbors=3,\n",
    "                 min_dist=0.1,\n",
    "                 metric='cosine').fit_transform(model._vq_vae._embedding.weight.data.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(proj[:,0], proj[:,1], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
