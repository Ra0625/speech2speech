{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import librosa.display\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data_np = (data[i].to(torch.device(\"cpu\"))).detach().numpy();\n",
    "    data_np = librosa.db_to_amplitude(data_np)\n",
    "    data_griffin_lim = librosa.griffinlim(data_np)\n",
    "    data_recon_np = (data_recon[i].to(torch.device(\"cpu\"))).detach().numpy();\n",
    "    data_recon_np = librosa.db_to_amplitude(data_recon_np)\n",
    "    data_recon_griffin_lim = librosa.griffinlim(data_recon_np)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    output_path = '/home/ubuntu/speech2speech/data/output/plots/300_db_lr1em3_raw_plot_' + str(i) + '.png'\n",
    "    source_aud_path = '/home/ubuntu/speech2speech/data/output/300_db_lr1em3_source_' + str(i) + '.wav'\n",
    "    target_aud_path = '/home/ubuntu/speech2speech/data/output/300_db_lr1em3_target_' + str(i) + '.wav'\n",
    "    \n",
    "    librosa.display.waveplot(data_griffin_lim, color = 'g')\n",
    "    plt.title('Source Audio')\n",
    "    plt.xlabel('')\n",
    "    plt.subplot(2,1,2, sharex=ax, sharey=ax)\n",
    "    plt.title('Target Audio')\n",
    "    librosa.display.waveplot(data_recon_griffin_lim, color = 'b')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(output_path)\n",
    "    \n",
    "    librosa.output.write_wav(source_aud_path,data_griffin_lim, 16384)\n",
    "    librosa.output.write_wav(target_aud_path,data_recon_griffin_lim, 16384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    data_np = (data[i].to(torch.device(\"cpu\"))).detach().numpy();\n",
    "    data_np = librosa.db_to_amplitude(data_np)\n",
    "    data_griffin_lim = librosa.griffinlim(data_np)\n",
    "    data_recon_np = (data_recon[i].to(torch.device(\"cpu\"))).detach().numpy();\n",
    "    data_recon_np = librosa.db_to_amplitude(data_recon_np)\n",
    "    data_recon_griffin_lim = librosa.griffinlim(data_recon_np)\n",
    "    \n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = plt.subplot(2,1,1)\n",
    "    output_path = '/home/ubuntu/voice_conversion/data/output/plots//300_db_lr1em3_spec_plot_' + str(i) + '.png'\n",
    "\n",
    "    librosa.display.specshow(data_np, sr=16384, x_axis='time', y_axis='log')\n",
    "    plt.title('Source Audio')\n",
    "    plt.xlabel('')\n",
    "    plt.colorbar()\n",
    "    plt.subplot(2,1,2, sharex=ax, sharey=ax)\n",
    "    plt.title('Target Audio')\n",
    "    librosa.display.specshow(data_recon_np, sr=16384, x_axis='time', y_axis='log')\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
